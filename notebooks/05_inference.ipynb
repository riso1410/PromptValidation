{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riso\\miniconda3\\envs\\prompt-validation\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prompt_classifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprompt_classifier\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdspy_gpt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPT4oMini\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprompt_classifier\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfasttext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastTextClassifier\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprompt_classifier\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodeling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnli_modernbert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ModernBERTNLI\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'prompt_classifier'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "import random\n",
    "import statistics\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from fastembed import TextEmbedding\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from tqdm import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from prompt_classifier.modeling.dspy_gpt import GPT4oMini\n",
    "from prompt_classifier.modeling.fasttext import FastTextClassifier\n",
    "from prompt_classifier.modeling.nli_modernbert import ModernBERTNLI\n",
    "\n",
    "load_dotenv()\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_prompts = pd.read_csv(\"data/processed/general_prompts.csv\")\n",
    "finance_prompts = pd.read_csv(\"data/processed/finance_prompts.csv\")\n",
    "\n",
    "finance_dataset = (\n",
    "    pd.concat([finance_prompts, general_prompts])\n",
    "    .sample(frac=1)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "general_prompts_interim = pd.read_csv(\"data/interim/general_prompts.csv\")\n",
    "finance_prompts_interim = pd.read_csv(\"data/interim/finance_prompts.csv\")\n",
    "\n",
    "finance_dataset_interim = (\n",
    "    pd.concat([finance_prompts_interim, general_prompts_interim])\n",
    "    .sample(frac=1)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "baai_embedding = TextEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\",\n",
    "    providers=[\"CUDAExecutionProvider\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_data = finance_dataset_interim.sample(n=800)\n",
    "test_data = finance_dataset_interim.drop(train_data.index).sample(n=4000)\n",
    "\n",
    "# GPT Classifier\n",
    "gpt_classifier = GPT4oMini(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    proxy_url=os.getenv(\"PROXY_URL\"),\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    domain=\"finance\",\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    ")\n",
    "\n",
    "try:\n",
    "    gpt_classifier.load_model(\"models/gpt-4o-mini-finance.json\")\n",
    "\n",
    "    test_predictions, test_actuals, test_latency = gpt_classifier.predict()\n",
    "    print(f\"Test Accuracy: {metrics.accuracy_score(test_actuals, test_predictions)}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error running GPT model: {e}\")\n",
    "\n",
    "\n",
    "try:\n",
    "    test_data = finance_dataset_interim.sample(n=30_000)\n",
    "    # ModernBERT Classifier\n",
    "    bert_classifier = ModernBERTNLI(domain=\"finance\")\n",
    "    bert_classifier.classifier.model.to(\"cuda\")\n",
    "\n",
    "    # Test predictions\n",
    "    test_predictions = []\n",
    "    test_times = []\n",
    "    for _, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "        start_time = time.perf_counter_ns()\n",
    "        pred = bert_classifier.predict(row[\"prompt\"])\n",
    "        test_predictions.append(pred)\n",
    "        test_times.append(time.perf_counter_ns() - start_time)\n",
    "\n",
    "    test_acc = metrics.accuracy_score(test_data[\"label\"], test_predictions)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error running ModernBERT model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = finance_dataset.sample(frac=0.7).reset_index(drop=True)\n",
    "test_data = finance_dataset.drop(train_data.index).reset_index(drop=True)\n",
    "\n",
    "actuals = []\n",
    "predictions = []\n",
    "prediction_times = []\n",
    "\n",
    "# fastText\n",
    "try:\n",
    "    fasttext_classifier = FastTextClassifier(train_data=train_data, test_data=test_data)\n",
    "    fasttext_classifier.model = joblib.load(\"models/fastText_finance_fasttext.bin\")\n",
    "\n",
    "    for _, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "        text = str(row[\"prompt\"])\n",
    "        query = text.replace(\"\\n\", \"\")\n",
    "\n",
    "        start_time = time.perf_counter_ns()\n",
    "        prediction = fasttext_classifier.model.predict(query)\n",
    "        end_time = time.perf_counter_ns()\n",
    "\n",
    "        prediction_times.append(end_time - start_time)\n",
    "\n",
    "        if prediction[0][0] == \"__label__1\":\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "\n",
    "        actuals.append(row[\"label\"])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error running fastText model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Embedding test data\n",
    "start_time = time.perf_counter_ns()\n",
    "test_embeds = np.array(list(baai_embedding.embed(test_data[\"prompt\"])))\n",
    "end_time = time.perf_counter_ns()\n",
    "embed_times = end_time - start_time\n",
    "\n",
    "mean_embed_time = embed_times / len(train_data + test_data)\n",
    "\n",
    "with open(\"models/SVM_finance_baai.pkl\", \"rb\") as svm_file:\n",
    "    svm_classifier = pkl.load(svm_file)\n",
    "\n",
    "with open(\"models/XGBoost_finance_baai.pkl\", \"rb\") as xgboost_file:\n",
    "    xgboost_classifier = pkl.load(xgboost_file)\n",
    "\n",
    "predictions = []\n",
    "prediction_times = []\n",
    "\n",
    "for _, test_embed in enumerate(test_embeds):\n",
    "    start_time = time.perf_counter_ns()\n",
    "    prediction = svm_classifier.predict(test_embed.reshape(1, -1))\n",
    "    end_time = time.perf_counter_ns()\n",
    "\n",
    "    prediction_times.append(end_time - start_time)\n",
    "    predictions.append(prediction[0])\n",
    "\n",
    "\n",
    "for _, test_embed in enumerate(test_embeds):\n",
    "    start_time = time.perf_counter_ns()\n",
    "    prediction = xgboost_classifier.predict(test_embed.reshape(1, -1))\n",
    "    end_time = time.perf_counter_ns()\n",
    "\n",
    "    prediction_times.append(end_time - start_time)\n",
    "    predictions.append(prediction[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-validation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

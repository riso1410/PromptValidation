{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Out-of-Domain Generalization: Hate Speech Detection\n",
    "\n",
    "This notebook evaluates how well domain-specific classifiers generalize to out-of-domain hate speech detection.\n",
    "We test various model architectures trained on domain classification to see if they can effectively identify hate speech.\n",
    "\n",
    "Key aspects evaluated:\n",
    "- Few-shot transfer capabilities using DSPy\n",
    "- Model robustness across different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Overview\n",
    "\n",
    "This notebook evaluates several classification models:\n",
    "1. **LLM-based**: Using Qwen 2.5 for zero-shot classification\n",
    "2. **BERT-based**: ModernBERT with NLI approach\n",
    "3. **Traditional ML**: \n",
    "   - fastText for efficient text classification\n",
    "   - SVM and XGBoost with different embeddings\n",
    "\n",
    "Each model is evaluated on hate speech detection as an out-of-domain task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Import dependencies and initialize models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riso\\miniconda3\\envs\\prompt-validation\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle as pkl\n",
    "import random\n",
    "import statistics\n",
    "import time\n",
    "from functools import partial\n",
    "\n",
    "import fasttext\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import pandas as pd\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "from fastembed import TextEmbedding\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from xgboost import XGBClassifier\n",
    "os.chdir('..')\n",
    "from prompt_classifier.metrics import evaluate_run\n",
    "from prompt_classifier.modeling.dspy_llm import LlmClassifier\n",
    "from prompt_classifier.modeling.fasttext import FastTextClassifier\n",
    "from prompt_classifier.modeling.nli_modernbert import ModernBERTNLI\n",
    "from prompt_classifier.modeling.widemlp import MLP\n",
    "\n",
    "load_dotenv()\n",
    "random.seed(22)\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Datasets\n",
    "\n",
    "Load various hate speech datasets for evaluation:\n",
    "- Jigsaw Toxicity\n",
    "- OLID\n",
    "- HateXplain\n",
    "- TUKE Slovak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Jigsaw dataset\n",
    "jigsaw_splits = {\n",
    "    \"train\": \"train_dataset.csv\",\n",
    "    \"validation\": \"val_dataset.csv\",\n",
    "    \"test\": \"test_dataset.csv\",\n",
    "}\n",
    "jigsaw_df = pd.read_csv(\n",
    "    \"hf://datasets/Arsive/toxicity_classification_jigsaw/\" + jigsaw_splits[\"validation\"]\n",
    ")\n",
    "\n",
    "jigsaw_df = jigsaw_df[\n",
    "    (jigsaw_df[\"toxic\"] == 1)\n",
    "    | (jigsaw_df[\"severe_toxic\"] == 1)\n",
    "    | (jigsaw_df[\"obscene\"] == 1)\n",
    "    | (jigsaw_df[\"threat\"] == 1)\n",
    "    | (jigsaw_df[\"insult\"] == 1)\n",
    "    | (jigsaw_df[\"identity_hate\"] == 1)\n",
    "]\n",
    "\n",
    "jigsaw_df = jigsaw_df.rename(columns={\"comment_text\": \"prompt\"})\n",
    "jigsaw_df[\"label\"] = 0\n",
    "jigsaw_df = jigsaw_df[[\"prompt\", \"label\"]]\n",
    "jigsaw_df = jigsaw_df.dropna(subset=[\"prompt\"])\n",
    "jigsaw_df = jigsaw_df[jigsaw_df[\"prompt\"].str.strip() != \"\"]\n",
    "\n",
    "# Load OLID dataset\n",
    "olid_splits = {\"train\": \"train.csv\", \"test\": \"test.csv\"}\n",
    "olid_df = pd.read_csv(\"hf://datasets/christophsonntag/OLID/\" + olid_splits[\"train\"])\n",
    "olid_df = olid_df.rename(columns={\"cleaned_tweet\": \"prompt\"})\n",
    "olid_df[\"label\"] = 0\n",
    "olid_df = olid_df[[\"prompt\", \"label\"]]\n",
    "olid_df = olid_df.dropna(subset=[\"prompt\"])\n",
    "olid_df = olid_df[olid_df[\"prompt\"].str.strip() != \"\"]\n",
    "\n",
    "# Load hateXplain dataset\n",
    "hateXplain = pd.read_parquet(\n",
    "    \"hf://datasets/nirmalendu01/hateXplain_filtered/data/train-00000-of-00001.parquet\"\n",
    ")\n",
    "hateXplain = hateXplain.rename(columns={\"test_case\": \"prompt\"})\n",
    "hateXplain = hateXplain[(hateXplain[\"gold_label\"] == \"hateful\")]\n",
    "hateXplain = hateXplain[[\"prompt\", \"label\"]]\n",
    "hateXplain[\"label\"] = 0\n",
    "hateXplain = hateXplain.dropna(subset=[\"prompt\"])\n",
    "hateXplain = hateXplain[hateXplain[\"prompt\"].str.strip() != \"\"]\n",
    "\n",
    "# Load TUKE Slovak dataset\n",
    "tuke_sk_splits = {\"train\": \"train.json\", \"test\": \"test.json\"}\n",
    "tuke_sk_df = pd.read_json(\n",
    "    \"hf://datasets/TUKE-KEMT/hate_speech_slovak/\" + tuke_sk_splits[\"train\"], lines=True\n",
    ")\n",
    "tuke_sk_df = tuke_sk_df.rename(columns={\"text\": \"prompt\"})\n",
    "tuke_sk_df = tuke_sk_df[tuke_sk_df[\"label\"] == 0]\n",
    "tuke_sk_df = tuke_sk_df[[\"prompt\", \"label\"]]\n",
    "tuke_sk_df = tuke_sk_df.dropna(subset=[\"prompt\"])\n",
    "tuke_sk_df = tuke_sk_df[tuke_sk_df[\"prompt\"].str.strip() != \"\"]\n",
    "\n",
    "# Load DKK dataset\n",
    "dkk = pd.read_parquet(\"data/test-00000-of-00001.parquet\")\n",
    "dkk = dkk.rename(columns={\"text\": \"prompt\"})\n",
    "dkk = dkk[dkk[\"label\"] == \"OFF\"].reset_index(drop=True)\n",
    "dkk[\"label\"] = 0\n",
    "dkk = dkk.dropna(subset=[\"prompt\"])\n",
    "dkk = dkk[dkk[\"prompt\"].str.strip() != \"\"]\n",
    "\n",
    "dkk_all = pd.read_parquet(\"data/test-00000-of-00001.parquet\")\n",
    "dkk_all = dkk_all.rename(columns={\"text\": \"prompt\"})\n",
    "dkk_all[\"label\"] = 0\n",
    "dkk_all = dkk_all.dropna(subset=[\"prompt\"])\n",
    "dkk_all = dkk_all[dkk_all[\"prompt\"].str.strip() != \"\"]\n",
    "\n",
    "datasets = {\n",
    "    \"jigsaw\": jigsaw_df,\n",
    "    \"olid\": olid_df,\n",
    "    \"hate_xplain\": hateXplain,\n",
    "    \"tuke_sk\": tuke_sk_df,\n",
    "    \"dkk\": dkk,\n",
    "    \"dkk_all\": dkk_all,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>....\\n\\n.... Edgar, it's Saturday night!  Why ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are a TWAT \\n\\nTWAT'TWAT'TWAT'TWAT'TWAT'TW...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Whatt a jew\\nMake real articles, not stupid sp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>You don't even clean your ass when you poop. N...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>You Stupid Piece Of Shit</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  label\n",
       "0  ....\\n\\n.... Edgar, it's Saturday night!  Why ...      0\n",
       "2  You are a TWAT \\n\\nTWAT'TWAT'TWAT'TWAT'TWAT'TW...      0\n",
       "3  Whatt a jew\\nMake real articles, not stupid sp...      0\n",
       "6  You don't even clean your ass when you poop. N...      0\n",
       "8                           You Stupid Piece Of Shit      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ask native americans take</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>go home drunk maga trump 2020</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazon investigating chinese employees selling...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>someone vetaken piece shit volcano</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>obama wanted liberals illegals move red states</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  label\n",
       "0                          ask native americans take      0\n",
       "1                      go home drunk maga trump 2020      0\n",
       "2  amazon investigating chinese employees selling...      0\n",
       "3                 someone vetaken piece shit volcano      0\n",
       "4     obama wanted liberals illegals move red states      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;user&gt; i am bit confused coz chinese ppl can n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this bitch in whataburger eating a burger with...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>laura loomer raped me while screaming at me in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and this is why i end up with nigger trainee d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>guilty until proven innocent unless you are a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  label\n",
       "0  <user> i am bit confused coz chinese ppl can n...      0\n",
       "1  this bitch in whataburger eating a burger with...      0\n",
       "2  laura loomer raped me while screaming at me in...      0\n",
       "3  and this is why i end up with nigger trainee d...      0\n",
       "4  guilty until proven innocent unless you are a ...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user19773 tak ja uz na dovolenke a kaudy den o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user8371 ak by vám to neprechádzalo tu mate</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user13335 nezaslúžia, ale o tom nie je reč. di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ked sa pyta ciganikova na vzdelanie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>user36201 uvidis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  label\n",
       "1  user19773 tak ja uz na dovolenke a kaudy den o...      0\n",
       "2        user8371 ak by vám to neprechádzalo tu mate      0\n",
       "3  user13335 nezaslúžia, ale o tom nie je reč. di...      0\n",
       "5                ked sa pyta ciganikova na vzdelanie      0\n",
       "6                                   user36201 uvidis      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NED MED SVENSKEN!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@USER ryger du hash. ???</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DANSKJÄVLAR</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hvorfor i den fucking store helvede skal man f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>De små får fri på vores skole fordi en knægt b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  label\n",
       "0                                  NED MED SVENSKEN!      0\n",
       "1                           @USER ryger du hash. ???      0\n",
       "2                                        DANSKJÄVLAR      0\n",
       "3  hvorfor i den fucking store helvede skal man f...      0\n",
       "4  De små får fri på vores skole fordi en knægt b...      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Der er syriske \"flygtninge\" som rejser til Ira...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Danmark = Vitryssland?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ja tvangsfjernelser af børn på urigtige oplysn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Han kan ikke Svensk og forventer et job. Hvis ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NED MED SVENSKEN!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  label\n",
       "0  Der er syriske \"flygtninge\" som rejser til Ira...      0\n",
       "1                             Danmark = Vitryssland?      0\n",
       "2  Ja tvangsfjernelser af børn på urigtige oplysn...      0\n",
       "3  Han kan ikke Svensk og forventer et job. Hvis ...      0\n",
       "4                                  NED MED SVENSKEN!      0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(jigsaw_df.head())\n",
    "display(olid_df.head())\n",
    "display(hateXplain.head())\n",
    "display(tuke_sk_df.head())\n",
    "display(dkk.head())\n",
    "display(dkk_all.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets Overview\n",
    "\n",
    "We use four major hate speech datasets:\n",
    "\n",
    "1. **Jigsaw Toxicity**\n",
    "   - Multi-label toxicity classification\n",
    "   - Includes toxic, severe_toxic, obscene, threat, insult, identity_hate labels\n",
    "\n",
    "2. **OLID (Offensive Language Identification Dataset)**\n",
    "   - Hierarchical labeling of offensive language\n",
    "   - Focuses on Twitter content\n",
    "\n",
    "3. **HateXplain**\n",
    "   - Annotated with rationales for hate speech\n",
    "   - Includes target community information\n",
    "\n",
    "4. **TUKE Slovak**\n",
    "   - Slovak language hate speech dataset\n",
    "   - Tests cross-lingual generalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Models\n",
    "\n",
    "Using multiple embedding approaches:\n",
    "- **BAAI BGE**: Optimized for semantic similarity\n",
    "- **MiniLM**: Efficient sentence transformers model\n",
    "- **TF-IDF**: Traditional bag-of-words approach\n",
    "\n",
    "These embeddings are used with SVM and XGBoost classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_folder = os.getcwd()\n",
    "print(current_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baai_embedding = TextEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\", providers=[\"CUDAExecutionProvider\"]\n",
    ")\n",
    "\n",
    "mini_embedding = TextEmbedding(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    providers=[\"CUDAExecutionProvider\"],\n",
    ")\n",
    "\n",
    "# TF-IDF\n",
    "tfidf_finance = pkl.load(open(\"models/tfidf_finance.pkl\", \"rb\"))\n",
    "tfidf_healthcare = pkl.load(open(\"models/tfidf_healthcare.pkl\", \"rb\"))\n",
    "tfidf_law = pkl.load(open(\"models/tfidf_law.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation Process\n",
    "\n",
    "For each dataset and model combination:\n",
    "1. Load pre-trained domain classifiers\n",
    "2. Process test samples through each domain classifier\n",
    "3. Combine predictions using OR logic (any domain=1 -> toxic=0)\n",
    "4. Calculate metrics:\n",
    "   - Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ollama_chat/qwen2.5:14b\"\n",
    "\n",
    "for domain, inference_df in datasets.items():\n",
    "    try:\n",
    "        llm_classifier_finance = LlmClassifier(\n",
    "            api_key=\"\",\n",
    "            api_base=\"http://localhost:11434\",\n",
    "            model_name=model_name,\n",
    "            domain=\"finance\",\n",
    "            train_data=inference_df,\n",
    "            test_data=inference_df,\n",
    "        )\n",
    "\n",
    "        llm_classifier_healthcare = LlmClassifier(\n",
    "            api_key=\"\",\n",
    "            api_base=\"http://localhost:11434\",\n",
    "            model_name=model_name,\n",
    "            domain=\"healthcare\",\n",
    "            train_data=inference_df,\n",
    "            test_data=inference_df,\n",
    "        )\n",
    "\n",
    "        llm_classifier_law = LlmClassifier(\n",
    "            api_key=\"\",\n",
    "            api_base=\"http://localhost:11434\",\n",
    "            model_name=model_name,\n",
    "            domain=\"law\",\n",
    "            train_data=inference_df,\n",
    "            test_data=inference_df,\n",
    "        )\n",
    "\n",
    "        # Load models\n",
    "        llm_classifier_finance.load_model(\"models/qwen2.5:14b-finance.json\")\n",
    "        llm_classifier_healthcare.load_model(\"models/qwen2.5:14b-healthcare.json\")\n",
    "        llm_classifier_law.load_model(\"models/qwen2.5:14b-law.json\")\n",
    "\n",
    "        predictions_llm = []\n",
    "        prediction_times_llm = []\n",
    "        actuals_llm = []\n",
    "\n",
    "        # Get predictions for each prompt\n",
    "        for _, row in tqdm(inference_df.iterrows(), total=len(inference_df)):\n",
    "            start_time = time.perf_counter_ns()\n",
    "\n",
    "            # Get predictions from all models\n",
    "            pred_finance = llm_classifier_finance.predict_single(row[\"prompt\"])\n",
    "            pred_healthcare = llm_classifier_healthcare.predict_single(row[\"prompt\"])\n",
    "            pred_law = llm_classifier_law.predict_single(row[\"prompt\"])\n",
    "\n",
    "            end_time = time.perf_counter_ns()\n",
    "            prediction_times_llm.append(end_time - start_time)\n",
    "\n",
    "            # If any model predicts 1, final prediction is 0\n",
    "            predictions_llm.append(\n",
    "                0 if (pred_finance == 1 or pred_healthcare == 1 or pred_law == 1) else 1\n",
    "            )\n",
    "            actuals_llm.append(row[\"label\"])\n",
    "\n",
    "        evaluate_run(\n",
    "            predictions=predictions_llm,\n",
    "            true_labels=actuals_llm,\n",
    "            latency=statistics.mean(prediction_times_llm),\n",
    "            domain=domain,\n",
    "            embed_model=\"qwen2.5\",\n",
    "            model_name=model_name,\n",
    "            train_acc=0.0,\n",
    "            cost=0.0,\n",
    "            training=False,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error running LLM model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModernBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_classifier_finance = ModernBERTNLI(domain=\"finance\")\n",
    "bert_classifier_healthcare = ModernBERTNLI(domain=\"healthcare\")\n",
    "bert_classifier_law = ModernBERTNLI(domain=\"law\")\n",
    "\n",
    "try:\n",
    "    # Move models to GPU\n",
    "    bert_classifier_finance.classifier.model.to(\"cuda\")\n",
    "    bert_classifier_healthcare.classifier.model.to(\"cuda\")\n",
    "    bert_classifier_law.classifier.model.to(\"cuda\")\n",
    "\n",
    "    for domain, inference_df in datasets.items():\n",
    "        predictions_bert = []\n",
    "        prediction_times_bert = []\n",
    "        actuals_bert = []\n",
    "        # Get predictions for each prompt\n",
    "        for _, row in tqdm(inference_df.iterrows(), total=len(inference_df)):\n",
    "            start_time = time.perf_counter_ns()\n",
    "\n",
    "            # Get predictions from all models\n",
    "            pred_finance = bert_classifier_finance.predict(row[\"prompt\"])\n",
    "            pred_healthcare = bert_classifier_healthcare.predict(row[\"prompt\"])\n",
    "            pred_law = bert_classifier_law.predict(row[\"prompt\"])\n",
    "\n",
    "            end_time = time.perf_counter_ns()\n",
    "            prediction_times_bert.append(end_time - start_time)\n",
    "\n",
    "            # If any model predicts 1, final prediction is 0\n",
    "            predictions_bert.append(\n",
    "                0 if (pred_finance == 1 or pred_healthcare == 1 or pred_law == 1) else 1\n",
    "            )\n",
    "            actuals_bert.append(row[\"label\"])\n",
    "\n",
    "    evaluate_run(\n",
    "        predictions=predictions_bert,\n",
    "        true_labels=actuals_bert,\n",
    "        latency=statistics.mean(prediction_times_bert),\n",
    "        domain=domain,\n",
    "        embed_model=\"BERT\",\n",
    "        model_name=\"ModernBERT\",\n",
    "        train_acc=0.0,\n",
    "        cost=0.0,\n",
    "        training=False,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"Error running ModernBERT models: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastText\n",
    "for domain, inference_df in datasets.items():\n",
    "    actuals_ft = []\n",
    "    predictions_ft = []\n",
    "    prediction_times_ft = []\n",
    "    print(f\"Processing dataset {domain}...\")\n",
    "    try:\n",
    "        # Try to load model with proper error handling\n",
    "        try:\n",
    "            fasttext_classifier_finance = FastTextClassifier(\n",
    "                train_data=inference_df, test_data=inference_df\n",
    "            )\n",
    "            fasttext_classifier_finance.model = fasttext.load_model(\n",
    "                \"models/fastText_finance_fasttext.bin\"\n",
    "            )\n",
    "\n",
    "            fasttext_classifier_healthcare = FastTextClassifier(\n",
    "                train_data=inference_df, test_data=inference_df\n",
    "            )\n",
    "            fasttext_classifier_healthcare.model = fasttext.load_model(\n",
    "                \"models/fastText_healthcare_fasttext.bin\"\n",
    "            )\n",
    "\n",
    "            fasttext_classifier_law = FastTextClassifier(\n",
    "                train_data=inference_df, test_data=inference_df\n",
    "            )\n",
    "            fasttext_classifier_law.model = fasttext.load_model(\n",
    "                \"models/fastText_law_fasttext.bin\"\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading fastText models: {e}\")\n",
    "            continue\n",
    "\n",
    "        for _, row in tqdm(inference_df.iterrows(), total=len(inference_df)):\n",
    "            text = str(row[\"prompt\"])\n",
    "            query = text.replace(\"\\n\", \"\")\n",
    "\n",
    "            try:\n",
    "                start_time = time.perf_counter_ns()\n",
    "\n",
    "                # Predictions from all three classifiers\n",
    "                prediction_finance = fasttext_classifier_finance.model.predict(query)\n",
    "                prediction_healthcare = fasttext_classifier_healthcare.model.predict(\n",
    "                    query\n",
    "                )\n",
    "                prediction_law = fasttext_classifier_law.model.predict(query)\n",
    "\n",
    "                end_time = time.perf_counter_ns()\n",
    "                prediction_times_ft.append(end_time - start_time)\n",
    "\n",
    "                predictions_ft.append(\n",
    "                    0\n",
    "                    if (\n",
    "                        prediction_finance[0][0] == \"__label__1\"\n",
    "                        or prediction_healthcare[0][0] == \"__label__1\"\n",
    "                        or prediction_law[0][0] == \"__label__1\"\n",
    "                    )\n",
    "                    else 1\n",
    "                )\n",
    "                actuals_ft.append(row[\"label\"])\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing row: {e}\")\n",
    "                continue\n",
    "\n",
    "        evaluate_run(\n",
    "            predictions=predictions_ft,\n",
    "            true_labels=actuals_ft,\n",
    "            latency=statistics.mean(prediction_times_ft),\n",
    "            domain=domain,\n",
    "            embed_model=\"fastText\",\n",
    "            model_name=\"fastText\",\n",
    "            train_acc=0.0,\n",
    "            cost=0.0,\n",
    "            training=False,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing dataset {domain}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML - SVM, XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_models_names = [\"mini\", \"baai\", \"tf_idf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding test data\n",
    "for embedding_model in embedding_models_names:\n",
    "    for domain, inference_df in datasets.items():\n",
    "        # Get actual labels once\n",
    "        actuals_ml = inference_df[\"label\"].tolist()\n",
    "\n",
    "        # Get embeddings based on model type\n",
    "        if embedding_model == \"tf_idf\":\n",
    "            test_embeds = tfidf_finance.transform(inference_df[\"prompt\"])\n",
    "        else:\n",
    "            start_time = time.perf_counter_ns()\n",
    "            if embedding_model == \"mini\":\n",
    "                test_embeds = np.array(\n",
    "                    list(mini_embedding.embed(inference_df[\"prompt\"]))\n",
    "                )\n",
    "            else:  # baai\n",
    "                test_embeds = np.array(\n",
    "                    list(baai_embedding.embed(inference_df[\"prompt\"]))\n",
    "                )\n",
    "            end_time = time.perf_counter_ns()\n",
    "            embed_times = end_time - start_time\n",
    "            mean_embed_time = embed_times / len(inference_df)\n",
    "\n",
    "        # Load models\n",
    "        try:\n",
    "            # Load SVM models\n",
    "            with open(f\"models/SVM_finance_{embedding_model}.pkl\", \"rb\") as f:\n",
    "                svm_classifier_finance = pkl.load(f)\n",
    "            with open(f\"models/SVM_healthcare_{embedding_model}.pkl\", \"rb\") as f:\n",
    "                svm_classifier_healthcare = pkl.load(f)\n",
    "            with open(f\"models/SVM_law_{embedding_model}.pkl\", \"rb\") as f:\n",
    "                svm_classifier_law = pkl.load(f)\n",
    "\n",
    "            # Load XGBoost models\n",
    "            xgb_classifier_finance = XGBClassifier()\n",
    "            xgb_classifier_healthcare = XGBClassifier()\n",
    "            xgb_classifier_law = XGBClassifier()\n",
    "\n",
    "            xgb_classifier_finance.load_model(\n",
    "                f\"models/XGBoost_finance_{embedding_model}.json\"\n",
    "            )\n",
    "            xgb_classifier_healthcare.load_model(\n",
    "                f\"models/XGBoost_healthcare_{embedding_model}.json\"\n",
    "            )\n",
    "            xgb_classifier_law.load_model(f\"models/XGBoost_law_{embedding_model}.json\")\n",
    "\n",
    "            predictions_xgb = []\n",
    "            predictions_svm = []\n",
    "            prediction_times_xgb = []\n",
    "            prediction_times_svm = []\n",
    "\n",
    "            # Make predictions\n",
    "            for test_embed in test_embeds:\n",
    "                test_embed = test_embed.reshape(1, -1)\n",
    "\n",
    "                # SVM predictions\n",
    "                start_time = time.perf_counter_ns()\n",
    "                pred_finance = svm_classifier_finance.predict(test_embed)\n",
    "                pred_healthcare = svm_classifier_healthcare.predict(test_embed)\n",
    "                pred_law = svm_classifier_law.predict(test_embed)\n",
    "                end_time = time.perf_counter_ns()\n",
    "\n",
    "                prediction_times_svm.append(end_time - start_time)\n",
    "                predictions_svm.append(\n",
    "                    0\n",
    "                    if (\n",
    "                        pred_finance[0] == 1\n",
    "                        or pred_healthcare[0] == 1\n",
    "                        or pred_law[0] == 1\n",
    "                    )\n",
    "                    else 1\n",
    "                )\n",
    "\n",
    "                # XGBoost predictions\n",
    "                start_time = time.perf_counter_ns()\n",
    "                pred_finance = xgb_classifier_finance.predict(test_embed)\n",
    "                pred_healthcare = xgb_classifier_healthcare.predict(test_embed)\n",
    "                pred_law = xgb_classifier_law.predict(test_embed)\n",
    "                end_time = time.perf_counter_ns()\n",
    "\n",
    "                prediction_times_xgb.append(end_time - start_time)\n",
    "                predictions_xgb.append(\n",
    "                    0\n",
    "                    if (\n",
    "                        pred_finance[0] == 1\n",
    "                        or pred_healthcare[0] == 1\n",
    "                        or pred_law[0] == 1\n",
    "                    )\n",
    "                    else 1\n",
    "                )\n",
    "\n",
    "            # Evaluate results\n",
    "            evaluate_run(\n",
    "                predictions=predictions_svm,\n",
    "                true_labels=actuals_ml,\n",
    "                latency=statistics.mean(prediction_times_svm),\n",
    "                domain=domain,\n",
    "                embed_model=embedding_model,\n",
    "                model_name=\"SVM\",\n",
    "                train_acc=0.0,\n",
    "                cost=0.0,\n",
    "                training=False,\n",
    "            )\n",
    "            evaluate_run(\n",
    "                predictions=predictions_xgb,\n",
    "                true_labels=actuals_ml,\n",
    "                latency=statistics.mean(prediction_times_xgb),\n",
    "                domain=domain,\n",
    "                embed_model=embedding_model,\n",
    "                model_name=\"XGBoost\",\n",
    "                train_acc=0.0,\n",
    "                cost=0.0,\n",
    "                training=False,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(\n",
    "                f\"Error processing {domain} dataset with {embedding_model} embeddings: {e}\"\n",
    "            )\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WideMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer function for batch processing\n",
    "tokenizer_func = partial(\n",
    "    tokenizer, padding=True, truncation=True, return_tensors=\"pt\", max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded PyTorch model on cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device for PyTorch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "wide_mlp_classifier = MLP(vocab_size=tokenizer.vocab_size, num_classes=3, problem_type=\"multi_label_classification\")\n",
    "\n",
    "# Load model states\n",
    "try:\n",
    "    checkpoint = torch.load('models_5/mlp_best_model.pt', weights_only=True)\n",
    "    wide_mlp_classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "    wide_mlp_classifier = wide_mlp_classifier.to(device)\n",
    "    wide_mlp_classifier.eval()\n",
    "    print(f'Successfully loaded PyTorch model on {device}')\n",
    "except Exception as e:\n",
    "    print(f'Error loading PyTorch model: {e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing jigsaw dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/101 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [2 1 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1 0 0 0 0 0 0]\n",
      "Error running Wide MLP inference: mean requires at least one data point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Wide MLP Inference\n",
    "try:\n",
    "    for domain, inference_df in datasets.items():\n",
    "        print(f'\\nProcessing {domain} dataset...')\n",
    "        predictions_wide_mlp = []\n",
    "        prediction_times_wide_mlp = []\n",
    "        actuals_wide_mlp = []\n",
    "\n",
    "        # Process batches for efficiency\n",
    "        batch_size = 32\n",
    "        for i in tqdm(range(0, len(inference_df), batch_size)):\n",
    "            batch = inference_df.iloc[i:i + batch_size]\n",
    "\n",
    "            start_time = time.perf_counter_ns()\n",
    "            inputs = tokenizer_func(list(batch['prompt']))\n",
    "\n",
    "            input_ids = inputs['input_ids'].to(device)\n",
    "            offsets = torch.arange(0, input_ids.numel(), input_ids.size(1), dtype=torch.long).to(device)\n",
    "            input_ids = input_ids.view(-1)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                outputs = wide_mlp_classifier(input_ids, offsets)\n",
    "                predictions = outputs.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "            end_time = time.perf_counter_ns()\n",
    "\n",
    "            prediction_times_wide_mlp.extend([end_time - start_time] * len(batch))\n",
    "            predictions_wide_mlp.extend([0 if pred == 1 else 1 for pred in predictions])\n",
    "            actuals_wide_mlp.extend(batch['label'].tolist())\n",
    "\n",
    "        # Evaluate results\n",
    "        evaluate_run(\n",
    "            predictions=predictions_wide_mlp,\n",
    "            true_labels=actuals_wide_mlp,\n",
    "            latency=statistics.mean(prediction_times_wide_mlp),\n",
    "            domain=domain,\n",
    "            embed_model='MiniLM-L12',\n",
    "            model_name='WideMLP',\n",
    "            train_acc=0.0,\n",
    "            cost=0.0,\n",
    "            training=False\n",
    "        )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'Error running Wide MLP inference: {e}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load ONNX models\n",
    "    mlp_classifier = ort.InferenceSession(\n",
    "        \"models_5/text_classifier_optimized_int8.onnx\",\n",
    "        providers=['CUDAExecutionProvider', 'CPUExecutionProvider']\n",
    "    )\n",
    "    print(\"Successfully loaded all ONNX models\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error loading ONNX models: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain, inference_df in datasets.items():\n",
    "    print(f\"\\nProcessing {domain} dataset...\")\n",
    "    predictions_mlp = []\n",
    "    prediction_times_mlp = []\n",
    "    actuals_mlp = []\n",
    "\n",
    "    try:\n",
    "        for _, row in tqdm(inference_df.iterrows(), total=len(inference_df)):\n",
    "            # Tokenize input text\n",
    "            start_time = time.perf_counter_ns()\n",
    "            inputs = tokenizer_func(row[\"prompt\"])\n",
    "\n",
    "            # Convert to numpy arrays for ONNX\n",
    "            onnx_inputs = {\n",
    "                'input_ids': inputs['input_ids'].numpy(),\n",
    "                'attention_mask': inputs['attention_mask'].numpy(),\n",
    "            }\n",
    "\n",
    "            # Run inference\n",
    "            pred = mlp_classifier.run(None, onnx_inputs)[0]\n",
    "            end_time = time.perf_counter_ns()\n",
    "\n",
    "            prediction_times_mlp.append(end_time - start_time)\n",
    "            predictions_mlp.append(0 if np.argmax(pred) == 1 else 1)\n",
    "            actuals_mlp.append(row[\"label\"])\n",
    "\n",
    "        # Evaluate results\n",
    "        evaluate_run(\n",
    "            predictions=predictions_mlp,\n",
    "            true_labels=actuals_mlp,\n",
    "            latency=statistics.mean(prediction_times_mlp),\n",
    "            domain=domain,\n",
    "            embed_model=\"MiniLM-L12\",\n",
    "            model_name=\"MLP-ONNX\",\n",
    "            train_acc=0.0,\n",
    "            cost=0.0,\n",
    "            training=False,\n",
    "        )\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {domain} dataset: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-validation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

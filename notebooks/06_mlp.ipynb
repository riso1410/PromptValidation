{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Layer Perceptron (MLP) Model Training\n",
    "\n",
    "This notebook implements a simple MLP classifier using PyTorch for domain classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "Import required libraries and set random seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from accelerate.data_loader import DataLoader\n",
    "from datasets import ClassLabel, Dataset, load_dataset\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from torch import nn as nn\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture\n",
    "\n",
    "Define helper functions and model architecture:\n",
    "- Mean pooling for handling variable length sequences\n",
    "- Dynamic Tanh (DyT) activation layer\n",
    "- MLP head with DyT activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "\n",
    "This implementation uses three domain-specific datasets:\n",
    "- **Finance**: Questions and answers from finance domain\n",
    "- **Health**: Healthcare related conversations from ChatDoctor\n",
    "- **Law**: Legal questions from Law Stack Exchange\n",
    "\n",
    "These datasets will be used to train a classifier that can identify the domain of input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(\n",
    "    model_output: torch.Tensor, attention_mask: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    token_embeddings = model_output[\n",
    "        0\n",
    "    ]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "        input_mask_expanded.sum(1), min=1e-9\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "model = model.cuda() if torch.cuda.is_available() else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finance = load_dataset(\"Marina-C/question-answer-Subject-Finance-Instruct\")\n",
    "health = load_dataset(\"iecjsu/lavita-ChatDoctor-HealthCareMagic-100k\")\n",
    "law = load_dataset(\"dim/law_stackexchange_prompts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finance_df = pd.DataFrame(\n",
    "    {\"messages\": [row[1][\"content\"] for row in finance[\"train\"][\"messages\"]]}\n",
    ")\n",
    "\n",
    "health_df = pd.DataFrame({\"messages\": health[\"train\"][\"input\"]})\n",
    "\n",
    "law_df = pd.DataFrame({\"messages\": law[\"train\"][\"prompt\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add labels\n",
    "finance_df[\"label\"] = 0\n",
    "health_df[\"label\"] = 1\n",
    "law_df[\"label\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([finance_df, health_df, law_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset = Dataset.from_pandas(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset = combined_dataset.cast_column(\n",
    "    \"label\", ClassLabel(num_classes=3, names=[\"finance\", \"health\", \"law\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "EARLY_STOP_PATIENCE = 5\n",
    "FREEZE_TRAIN_LR = 1e-4\n",
    "UNFROZEN_TRAIN_LR_WARMUP = 1e-6\n",
    "UNFROZEN_TRAIN_LR = 1e-5\n",
    "WARMUP_STEPS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_func = partial(\n",
    "    tokenizer, padding=True, truncation=True, return_tensors=\"pt\", max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = tokenizer_func(combined_dataset[\"messages\"][0]).to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.forward(**encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = mean_pooling(out, encoded[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = F.normalize(out, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Components\n",
    "\n",
    "The model architecture consists of several key components:\n",
    "\n",
    "1. **Base Model**: Using sentence-transformers/all-MiniLM-L6-v2 for text embeddings\n",
    "2. **Mean Pooling**: Converts variable length sequences to fixed size embeddings\n",
    "3. **DyT Activation**: Dynamic Tanh activation function with learnable parameters\n",
    "4. **MLP Head**: Multi-layer perceptron classifier with DyT activations\n",
    "\n",
    "The training process is split into two phases:\n",
    "1. Training with frozen backbone weights\n",
    "2. Fine-tuning the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DyT(nn.Module):\n",
    "    def __init__(self, hidden_size: int, init_alpha: float = 0.5) -> None:\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.ones(1) * init_alpha)\n",
    "        self.gamma = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.beta = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.gamma * torch.tanh(self.alpha * x) + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_classes: int) -> None:\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 128),\n",
    "            DyT(128),\n",
    "            nn.Linear(128, 64),\n",
    "            DyT(64),\n",
    "            nn.Linear(64, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.head = Head(384, 3).to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_frozen = AdamW(model.head.parameters(), lr=FREEZE_TRAIN_LR, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scaler = torch.GradScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing\n",
    "\n",
    "Load domain-specific datasets and prepare them for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataset = combined_dataset.train_test_split(\n",
    "    test_size=0.1, stratify_by_column=\"label\"\n",
    ")\n",
    "train_dataset = combined_dataset[\"train\"]\n",
    "test_dataset = combined_dataset[\"test\"]\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_frozen() -> None:\n",
    "    model.eval()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    model.head.train()\n",
    "    for param in model.head.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    last_test_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    for epoch in range(3):\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            optim_frozen.zero_grad()\n",
    "            input_msg = batch[\"messages\"]\n",
    "            input = tokenizer_func(input_msg).to(model.device)\n",
    "            target = batch[\"label\"].to(model.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out = model.forward(**input)\n",
    "                out = mean_pooling(out, input[\"attention_mask\"])\n",
    "                out = F.normalize(out, p=2, dim=1)\n",
    "\n",
    "            out = model.head(out)\n",
    "            loss = criterion(out, target)\n",
    "            loss.backward()\n",
    "            optim_frozen.step()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            losses = []\n",
    "            for batch in test_dataloader:\n",
    "                input_msg = batch[\"messages\"]\n",
    "                input = tokenizer_func(input_msg).to(model.device)\n",
    "                target = batch[\"label\"].to(model.device)\n",
    "                out = model.forward(**input)\n",
    "                out = mean_pooling(out, input[\"attention_mask\"])\n",
    "                out = F.normalize(out, p=2, dim=1)\n",
    "                out = model.head(out)\n",
    "                loss = criterion(out, target)\n",
    "                losses.append(loss.item())\n",
    "            test_loss = sum(losses) / len(losses)\n",
    "            print(f\"Test loss: {test_loss}\")\n",
    "            if test_loss < last_test_loss:\n",
    "                last_test_loss = test_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "        if patience_counter >= EARLY_STOP_PATIENCE:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frozen()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "Train the model in two phases:\n",
    "1. Train with frozen backbone weights\n",
    "2. Fine-tune the full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Jigsaw dataset\n",
    "jigsaw_splits = {'train': 'train_dataset.csv', 'validation': 'val_dataset.csv', 'test': 'test_dataset.csv'}\n",
    "jigsaw_df = pd.read_csv(\"hf://datasets/Arsive/toxicity_classification_jigsaw/\" + jigsaw_splits[\"validation\"])\n",
    "\n",
    "jigsaw_df = jigsaw_df[(jigsaw_df[\"toxic\"] == 1) |\n",
    "                            (jigsaw_df[\"severe_toxic\"] == 1) |\n",
    "                            (jigsaw_df[\"obscene\"] == 1) |\n",
    "                            (jigsaw_df[\"threat\"] == 1) |\n",
    "                            (jigsaw_df[\"insult\"] == 1) |\n",
    "                            (jigsaw_df[\"identity_hate\"] == 1)]\n",
    "\n",
    "jigsaw_df = jigsaw_df.rename(columns={\"comment_text\": \"messages\"})\n",
    "jigsaw_df[\"label\"] = 0\n",
    "jigsaw_df = jigsaw_df.dropna(subset=[\"messages\"])\n",
    "jigsaw_df = jigsaw_df[[\"messages\", \"label\"]]\n",
    "\n",
    "# Load OLID dataset\n",
    "olid_splits = {'train': 'train.csv', 'test': 'test.csv'}\n",
    "olid_df = pd.read_csv(\"hf://datasets/christophsonntag/OLID/\" + olid_splits[\"train\"])\n",
    "\n",
    "olid_df = olid_df.rename(columns={\"cleaned_tweet\": \"messages\"})\n",
    "olid_df[\"label\"] = 0\n",
    "olid_df = olid_df.dropna(subset=[\"messages\"])\n",
    "olid_df = olid_df[[\"messages\", \"label\"]]\n",
    "\n",
    "# Load hateXplain dataset\n",
    "hateXplain = pd.read_parquet(\"hf://datasets/nirmalendu01/hateXplain_filtered/data/train-00000-of-00001.parquet\")\n",
    "hateXplain = hateXplain.rename(columns={\"test_case\": \"messages\"})\n",
    "hateXplain = hateXplain[(hateXplain[\"gold_label\"] == \"hateful\")]\n",
    "hateXplain = hateXplain.rename(columns={\"gold_label\": \"label\"})\n",
    "hateXplain = hateXplain[[\"messages\", \"label\"]]\n",
    "hateXplain = hateXplain.dropna(subset=[\"messages\"])\n",
    "\n",
    "# Load TUKE slovak dataset\n",
    "tuke_sk_splits = {'train': 'train.json', 'test': 'test.json'}\n",
    "tuke_sk_df = pd.read_json(\"hf://datasets/TUKE-KEMT/hate_speech_slovak/\" + tuke_sk_splits[\"train\"])\n",
    "tuke_sk_df = tuke_sk_df.rename(columns={\"text\": \"messages\"})\n",
    "tuke_sk_df = tuke_sk_df[tuke_sk_df[\"label\"] == 0]\n",
    "tuke_sk_df = tuke_sk_df[[\"messages\", \"label\"]]\n",
    "tuke_sk_df = tuke_sk_df.dropna(subset=[\"messages\"])\n",
    "\n",
    "datasets = [jigsaw_df, olid_df, hateXplain, tuke_sk_df]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders for each hate speech dataset\n",
    "inference_dataloaders = []\n",
    "\n",
    "for dataset_df in datasets:\n",
    "    # Convert DataFrame to Dataset\n",
    "    dataset = Dataset.from_pandas(dataset_df)\n",
    "    \n",
    "    # Create DataLoader\n",
    "    dataloader = DataLoader(\n",
    "        dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False\n",
    "    )\n",
    "    inference_dataloaders.append(dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on Hate Speech Datasets\n",
    "\n",
    "The model is evaluated on multiple hate speech datasets to assess cross-domain performance:\n",
    "- Jigsaw Toxicity Classification\n",
    "- OLID (Offensive Language Identification)\n",
    "- HateXplain\n",
    "- TUKE Slovak Hate Speech\n",
    "\n",
    "This helps understand how well the domain classifier handles potentially harmful content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(inference_dataloader: DataLoader) -> float:\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(inference_dataloader, desc=\"Evaluating\"):\n",
    "            input_msg = batch[\"messages\"]\n",
    "            input = tokenizer_func(input_msg).to(model.device)\n",
    "            target = batch[\"label\"].to(model.device)\n",
    "\n",
    "            # Get embeddings from base model\n",
    "            out = model.forward(**input)\n",
    "            out = mean_pooling(out, input[\"attention_mask\"])\n",
    "            out = F.normalize(out, p=2, dim=1)\n",
    "\n",
    "            # Forward through head\n",
    "            logits = model.head(out)\n",
    "\n",
    "            # Get predictions\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            # Calculate accuracy\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "for dataset in inference_dataloaders:\n",
    "    # Evaluate on each dataset\n",
    "    print(f\"Evaluating on dataset with {len(dataset.dataset)} samples\")\n",
    "    accuracy = evaluate_accuracy(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization\n",
    "\n",
    "The confusion matrix shows the model's performance across domains:\n",
    "- Diagonal elements represent correct classifications\n",
    "- Off-diagonal elements show misclassifications between domains\n",
    "\n",
    "Additional metrics calculated:\n",
    "- Accuracy: Overall correct predictions\n",
    "- Precision: True positives / (True positives + False positives)\n",
    "- Recall: True positives / (True positives + False negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix() -> None:\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Collecting predictions\"):\n",
    "            input_msg = batch[\"messages\"]\n",
    "            input = tokenizer_func(input_msg).to(model.device)\n",
    "            target = batch[\"label\"].to(model.device)\n",
    "\n",
    "            out = model.forward(**input)\n",
    "            out = mean_pooling(out, input[\"attention_mask\"])\n",
    "            out = F.normalize(out, p=2, dim=1)\n",
    "            logits = model.head(out)\n",
    "\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    precision, recall, _, _ = precision_recall_fscore_support(all_targets, all_predictions, average=None)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=combined_dataset[\"test\"].features[\"label\"].names,\n",
    "        yticklabels=combined_dataset[\"test\"].features[\"label\"].names,\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Plot the confusion matrix\n",
    "plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP \n",
    "- author: Tibor Sloboda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils.prune as prune\n",
    "from accelerate.data_loader import DataLoader\n",
    "from datasets import ClassLabel, Dataset, load_dataset\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch import nn as nn\n",
    "from torch.optim import Adam, AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModel, AutoTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (\n",
    "    torch.cuda.get_device_capability(0)[0] >= 8\n",
    "):  # A100 is Ampere architecture (compute capability 8.0+)\n",
    "    # Enable sparse tensor cores\n",
    "    torch.backends.cuda.matmul.allow_tf32 = (\n",
    "        True  # This enables TF32 which works with the sparse cores\n",
    "    )\n",
    "    # For specific sparse operations\n",
    "    torch.set_float32_matmul_precision(\"high\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSwiGLU(nn.Module):\n",
    "    def __init__(self, in_features: int):\n",
    "        super().__init__()\n",
    "\n",
    "        assert in_features % 2 == 0, \"in_features must be even\"\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.linear1 = nn.Linear(in_features // 2, in_features // 2)\n",
    "        self.linear2 = nn.Linear(in_features // 2, in_features // 2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x1, x2 = x.chunk(2, dim=-1)\n",
    "        x1 = self.linear1(x1)\n",
    "        x2 = self.linear2(x2)\n",
    "        return F.silu(x1) * x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DyT(nn.Module):\n",
    "    def __init__(self, hidden_size: int, init_alpha: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.ones(1) * init_alpha)\n",
    "        self.gamma = nn.Parameter(torch.ones(hidden_size))\n",
    "        self.beta = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.gamma * torch.tanh(self.alpha * x) + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, hidden_size: int, num_classes: int):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 256),\n",
    "            nn.Tanh(),\n",
    "            DyT(256),\n",
    "            CustomSwiGLU(256),\n",
    "            DyT(128),\n",
    "            CustomSwiGLU(128),\n",
    "            nn.AlphaDropout(0.15),\n",
    "            DyT(64),\n",
    "            CustomSwiGLU(64),\n",
    "            nn.AlphaDropout(0.05),\n",
    "            DyT(32),\n",
    "            CustomSwiGLU(32),\n",
    "            DyT(16),\n",
    "            nn.Linear(16, num_classes),\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def device(self):\n",
    "        return next(self.parameters()).device\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.seq(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_frozen():\n",
    "    model.eval()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    head.train()\n",
    "    for param in head.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    last_test_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "\n",
    "    while True:\n",
    "        for batch in tqdm(train_dataloader):\n",
    "            optim_frozen.zero_grad()\n",
    "            input_msg = batch[\"messages\"]\n",
    "            input = tokenizer_func(input_msg).to(model.device)\n",
    "            target = batch[\"label\"].to(model.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                out = model.forward(**input)\n",
    "                out = mean_pooling(out, input[\"attention_mask\"])\n",
    "                out = F.normalize(out, p=2, dim=1)\n",
    "\n",
    "            out = head(out)\n",
    "            loss = criterion(out, target)\n",
    "\n",
    "            loss.backward()\n",
    "            optim_frozen.step()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            losses = []\n",
    "            for batch in test_dataloader:\n",
    "                input_msg = batch[\"messages\"]\n",
    "                input = tokenizer_func(input_msg).to(model.device)\n",
    "                target = batch[\"label\"].to(model.device)\n",
    "                out = model.forward(**input)\n",
    "                out = mean_pooling(out, input[\"attention_mask\"])\n",
    "                out = F.normalize(out, p=2, dim=1)\n",
    "                out = head(out)\n",
    "                loss = criterion(out, target)\n",
    "                losses.append(loss.item())\n",
    "            test_loss = sum(losses) / len(losses)\n",
    "            print(f\"Test loss: {test_loss}\")\n",
    "            if test_loss < last_test_loss:\n",
    "                last_test_loss = test_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "        if patience_counter >= EARLY_STOP_PATIENCE:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy():\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "            input_msg = batch[\"messages\"]\n",
    "            input = tokenizer_func(input_msg).to(model.device)\n",
    "            target = batch[\"label\"].to(model.device)\n",
    "\n",
    "            out = model.forward(**input)\n",
    "            out = mean_pooling(out, input[\"attention_mask\"])\n",
    "            out = F.normalize(out, p=2, dim=1)\n",
    "\n",
    "            logits = head(out)\n",
    "\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    class_correct = [0, 0, 0]\n",
    "    class_total = [0, 0, 0]\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Class accuracy\"):\n",
    "            input_msg = batch[\"messages\"]\n",
    "            input = tokenizer_func(input_msg).to(model.device)\n",
    "            target = batch[\"label\"].to(model.device)\n",
    "\n",
    "            out = model.forward(**input)\n",
    "            out = mean_pooling(out, input[\"attention_mask\"])\n",
    "            out = F.normalize(out, p=2, dim=1)\n",
    "            logits = head(out)\n",
    "\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            # Calculate per-class accuracy\n",
    "            for i in range(target.size(0)):\n",
    "                label = target[i].item()\n",
    "                class_total[label] += 1\n",
    "                if predicted[i] == target[i]:\n",
    "                    class_correct[label] += 1\n",
    "\n",
    "    for i in range(3):\n",
    "        class_name = combined_dataset[\"test\"].features[\"label\"].names[i]\n",
    "        class_acc = 100 * class_correct[i] / class_total[i]\n",
    "        print(f\"Accuracy of {class_name}: {class_acc:.2f}%\")\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix():\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Collecting predictions\"):\n",
    "            input_msg = batch[\"messages\"]\n",
    "            input = tokenizer_func(input_msg).to(model.device)\n",
    "            target = batch[\"label\"].to(model.device)\n",
    "\n",
    "            out = model.forward(**input)\n",
    "            out = mean_pooling(out, input[\"attention_mask\"])\n",
    "            out = F.normalize(out, p=2, dim=1)\n",
    "            logits = head(out)\n",
    "\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_targets, all_predictions)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=combined_dataset[\"test\"].features[\"label\"].names,\n",
    "        yticklabels=combined_dataset[\"test\"].features[\"label\"].names,\n",
    "    )\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_unfrozen(previous_head_optim=None):\n",
    "    base_optim = Adam(model.parameters(), lr=UNFROZEN_TRAIN_LR_WARMUP)\n",
    "\n",
    "    if previous_head_optim is not None:\n",
    "        head_optim = AdamW(head.parameters(), lr=FREEZE_TRAIN_LR, weight_decay=0.01)\n",
    "        head_optim.load_state_dict(previous_head_optim.state_dict())\n",
    "    else:\n",
    "        head_optim = AdamW(head.parameters(), lr=FREEZE_TRAIN_LR, weight_decay=0.01)\n",
    "\n",
    "    total_steps = len(train_dataloader) * 5  # Assuming 5 epochs as a cycle\n",
    "    scheduler = CosineAnnealingLR(\n",
    "        base_optim, T_max=total_steps, eta_min=UNFROZEN_TRAIN_LR_WARMUP\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "    head.train()\n",
    "\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = True\n",
    "    for param in head.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "    last_test_loss = float(\"inf\")\n",
    "    patience_counter = 0\n",
    "    step_counter = 0\n",
    "\n",
    "    while True:\n",
    "        for batch in tqdm(train_dataloader, desc=\"Training unfrozen\"):\n",
    "            base_optim.zero_grad()\n",
    "            head_optim.zero_grad()\n",
    "\n",
    "            input_msg = batch[\"messages\"]\n",
    "            input = tokenizer_func(input_msg).to(model.device)\n",
    "            target = batch[\"label\"].to(model.device)\n",
    "\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.bfloat16):\n",
    "                out = model.forward(**input)\n",
    "                out = mean_pooling(out, input[\"attention_mask\"])\n",
    "                out = F.normalize(out, p=2, dim=1)\n",
    "\n",
    "                logits = head(out)\n",
    "                loss = criterion(logits, target)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(base_optim)\n",
    "            scaler.step(head_optim)\n",
    "            scaler.update()\n",
    "\n",
    "            step_counter += 1\n",
    "            if step_counter == WARMUP_STEPS:\n",
    "                print(f\"Increasing learning rate after {WARMUP_STEPS} steps\")\n",
    "                for param_group in base_optim.param_groups:\n",
    "                    param_group[\"lr\"] = UNFROZEN_TRAIN_LR\n",
    "            scheduler.step()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            losses = []\n",
    "            for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "                input_msg = batch[\"messages\"]\n",
    "                input = tokenizer_func(input_msg).to(model.device)\n",
    "                target = batch[\"label\"].to(model.device)\n",
    "\n",
    "                out = model.forward(**input)\n",
    "                out = mean_pooling(out, input[\"attention_mask\"])\n",
    "                out = F.normalize(out, p=2, dim=1)\n",
    "                logits = head(out)\n",
    "\n",
    "                loss = criterion(logits, target)\n",
    "                losses.append(loss.item())\n",
    "\n",
    "            test_loss = sum(losses) / len(losses)\n",
    "            print(f\"Test loss: {test_loss:.6f}\")\n",
    "\n",
    "            if test_loss < last_test_loss:\n",
    "                last_test_loss = test_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= EARLY_STOP_PATIENCE:\n",
    "                print(\n",
    "                    f\"Early stopping triggered after {patience_counter} epochs without improvement\"\n",
    "                )\n",
    "                break\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_training_pipeline():\n",
    "    train_frozen()\n",
    "\n",
    "    # Evaluate after first phase\n",
    "    evaluate_accuracy()\n",
    "\n",
    "    # save head\n",
    "    save_model(head, \"head.pt\")\n",
    "\n",
    "    train_unfrozen(previous_head_optim=optim_frozen)\n",
    "\n",
    "    # Final evaluation\n",
    "    evaluate_accuracy()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(\n",
    "    model_output: torch.Tensor, attention_mask: torch.Tensor\n",
    ") -> torch.Tensor:\n",
    "    token_embeddings = model_output[\n",
    "        0\n",
    "    ]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "        input_mask_expanded.sum(1), min=1e-9\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model: nn.Module, path: str) -> None:\n",
    "    # Save only the head's state dictionary\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(f\"Model head saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EARLY_STOP_PATIENCE = 5\n",
    "FREEZE_TRAIN_LR = 1e-4\n",
    "UNFROZEN_TRAIN_LR_WARMUP = 1e-6\n",
    "UNFROZEN_TRAIN_LR = 1e-5\n",
    "WARMUP_STEPS = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ee7fd2887d4807b30a567118e1e500",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/83143 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "finance = load_dataset(\"Marina-C/question-answer-Subject-Finance-Instruct\")\n",
    "health = load_dataset(\"iecjsu/lavita-ChatDoctor-HealthCareMagic-100k\")\n",
    "law = load_dataset(\"dim/law_stackexchange_prompts\")\n",
    "\n",
    "finance_df = pd.DataFrame(\n",
    "    {\"messages\": [row[1][\"content\"] for row in finance[\"train\"][\"messages\"]]}\n",
    ")\n",
    "\n",
    "health_df = pd.DataFrame({\"messages\": health[\"train\"][\"input\"]})\n",
    "\n",
    "law_df = pd.DataFrame({\"messages\": law[\"train\"][\"prompt\"]})\n",
    "\n",
    "# Add labels\n",
    "finance_df[\"label\"] = 0\n",
    "health_df[\"label\"] = 1\n",
    "law_df[\"label\"] = 2\n",
    "\n",
    "combined_df = pd.concat([finance_df, health_df, law_df], ignore_index=True)\n",
    "combined_dataset = Dataset.from_pandas(combined_df)\n",
    "combined_dataset = combined_dataset.cast_column(\n",
    "    \"label\", ClassLabel(num_classes=3, names=[\"finance\", \"health\", \"law\"])\n",
    ")\n",
    "combined_dataset = combined_dataset.train_test_split(\n",
    "    test_size=0.15, stratify_by_column=\"label\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights:\n",
      "Class 0 (finance): 0.7143\n",
      "Class 1 (health): 1.3858\n",
      "Class 2 (law): 1.1385\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights to handle class imbalance\n",
    "labels = combined_dataset[\"train\"][\"label\"]\n",
    "unique, counts = np.unique(labels, return_counts=True)\n",
    "total_samples = len(labels)\n",
    "\n",
    "# Compute weights inversely proportional to class frequencies\n",
    "class_weights = total_samples / (len(unique) * counts)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float)\n",
    "\n",
    "print(f\"Class weights:\")\n",
    "print(f\"Class 0 (finance): {class_weights[0]:.4f}\")\n",
    "print(f\"Class 1 (health): {class_weights[1]:.4f}\")\n",
    "print(f\"Class 2 (law): {class_weights[2]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = combined_dataset[\"train\"]\n",
    "test_dataset = combined_dataset[\"test\"]\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=1, pin_memory=True\n",
    ")\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "tokenizer_func = partial(\n",
    "    tokenizer, padding=True, truncation=True, return_tensors=\"pt\", max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = (\n",
    "    AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L12-v2\").train().cuda(0)\n",
    ")\n",
    "head = Head(384, 3).train().to(model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ixenr\\AppData\\Local\\Temp\\ipykernel_54992\\1762986478.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.model = torch.load(\"model.pt\")\n",
      "C:\\Users\\ixenr\\AppData\\Local\\Temp\\ipykernel_54992\\1762986478.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  head = torch.load(\"head.pt\")\n"
     ]
    }
   ],
   "source": [
    "model.model = torch.load(\"model.pt\")\n",
    "head = torch.load(\"head.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_frozen = AdamW(head.parameters(), lr=FREEZE_TRAIN_LR, weight_decay=0.01)\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights.to(model.device))\n",
    "scaler = torch.GradScaler()\n",
    "head_scaler = torch.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frozen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_training_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model head saved to head.pt\n"
     ]
    }
   ],
   "source": [
    "save_model(head, \"head.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training unfrozen:  46%|████▋     | 513/1105 [01:15<01:13,  8.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Increasing learning rate after 512 steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training unfrozen: 100%|██████████| 1105/1105 [02:29<00:00,  7.38it/s]\n",
      "Evaluating: 100%|██████████| 195/195 [00:14<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.007532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training unfrozen: 100%|██████████| 1105/1105 [02:24<00:00,  7.67it/s]\n",
      "Evaluating: 100%|██████████| 195/195 [00:14<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.005576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training unfrozen: 100%|██████████| 1105/1105 [02:24<00:00,  7.63it/s]\n",
      "Evaluating: 100%|██████████| 195/195 [00:14<00:00, 13.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.004299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training unfrozen: 100%|██████████| 1105/1105 [02:24<00:00,  7.62it/s]\n",
      "Evaluating: 100%|██████████| 195/195 [00:14<00:00, 13.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.003625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training unfrozen: 100%|██████████| 1105/1105 [02:22<00:00,  7.74it/s]\n",
      "Evaluating: 100%|██████████| 195/195 [00:14<00:00, 13.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.004443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training unfrozen: 100%|██████████| 1105/1105 [02:39<00:00,  6.93it/s]\n",
      "Evaluating: 100%|██████████| 195/195 [00:17<00:00, 11.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.003602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training unfrozen: 100%|██████████| 1105/1105 [02:33<00:00,  7.21it/s]\n",
      "Evaluating: 100%|██████████| 195/195 [00:13<00:00, 14.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.004004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training unfrozen: 100%|██████████| 1105/1105 [02:16<00:00,  8.10it/s]\n",
      "Evaluating: 100%|██████████| 195/195 [00:13<00:00, 14.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.003859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training unfrozen: 100%|██████████| 1105/1105 [02:40<00:00,  6.87it/s]\n",
      "Evaluating: 100%|██████████| 195/195 [00:16<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.005903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training unfrozen: 100%|██████████| 1105/1105 [02:46<00:00,  6.64it/s]\n",
      "Evaluating: 100%|██████████| 195/195 [00:17<00:00, 11.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.004746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training unfrozen: 100%|██████████| 1105/1105 [02:44<00:00,  6.73it/s]\n",
      "Evaluating: 100%|██████████| 195/195 [00:16<00:00, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.004725\n",
      "Early stopping triggered after 5 epochs without improvement\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 384)\n",
       "    (token_type_embeddings): Embedding(2, 384)\n",
       "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_unfrozen(previous_head_optim=optim_frozen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 195/195 [00:13<00:00, 14.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 99.95%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class accuracy: 100%|██████████| 195/195 [00:14<00:00, 13.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of finance: 99.97%\n",
      "Accuracy of health: 99.97%\n",
      "Accuracy of law: 99.92%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99.95189223861449"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Collecting predictions: 100%|██████████| 195/195 [00:13<00:00, 14.70it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model head saved to head.pt\n"
     ]
    }
   ],
   "source": [
    "save_model(head, \"head.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model head saved to model.pt\n"
     ]
    }
   ],
   "source": [
    "save_model(model, \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ixenr\\AppData\\Local\\Temp\\ipykernel_54092\\3457885924.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"model.pt\"))\n",
      "C:\\Users\\ixenr\\AppData\\Local\\Temp\\ipykernel_54092\\3457885924.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  head.load_state_dict(torch.load(\"head.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = (\n",
    "    AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L12-v2\").train().cuda(0)\n",
    ")\n",
    "head = Head(384, 3).train().to(model.device)\n",
    "model.load_state_dict(torch.load(\"model.pt\"))\n",
    "head.load_state_dict(torch.load(\"head.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModel(\n",
       "  (model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 384)\n",
       "      (token_type_embeddings): Embedding(2, 384)\n",
       "      (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (head): Head(\n",
       "    (seq): Sequential(\n",
       "      (0): Linear(in_features=384, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): DyT()\n",
       "      (3): CustomSwiGLU(\n",
       "        (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (linear2): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "      (4): DyT()\n",
       "      (5): CustomSwiGLU(\n",
       "        (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (6): AlphaDropout(p=0.15, inplace=False)\n",
       "      (7): DyT()\n",
       "      (8): CustomSwiGLU(\n",
       "        (linear1): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (linear2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      )\n",
       "      (9): AlphaDropout(p=0.05, inplace=False)\n",
       "      (10): DyT()\n",
       "      (11): CustomSwiGLU(\n",
       "        (linear1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (linear2): Linear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "      (12): DyT()\n",
       "      (13): Linear(in_features=16, out_features=3, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, model, head):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.head = head\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.model.forward(**input)\n",
    "        out = mean_pooling(out, input[\"attention_mask\"])\n",
    "        out = F.normalize(out, p=2, dim=1)\n",
    "        return self.head(out)\n",
    "\n",
    "\n",
    "custom_model = CustomModel(model, head)\n",
    "custom_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_model_to_onnx(model, save_path, input_shape=(1, 512), device=\"cuda\"):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Create dummy input for tracing\n",
    "    input_ids = torch.ones(input_shape, dtype=torch.long).to(device)\n",
    "    attention_mask = torch.ones(input_shape, dtype=torch.long).to(device)\n",
    "\n",
    "    sample_input = {\"input_ids\": input_ids, \"attention_mask\": attention_mask}\n",
    "\n",
    "    # Package inputs into a dictionary like the model expects\n",
    "    dummy_input = {\"input\": sample_input}\n",
    "\n",
    "    # Export the model with optimization options\n",
    "    torch.onnx.export(\n",
    "        model,  # model being run\n",
    "        dummy_input,  # model input (or a tuple for multiple inputs)\n",
    "        save_path,  # where to save the model\n",
    "        export_params=True,  # store the trained parameter weights inside the model file\n",
    "        opset_version=16,  # the ONNX version to export the model to\n",
    "        do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "        input_names=[\"input_ids\", \"attention_mask\"],  # the model's input names\n",
    "        output_names=[\"output\"],  # the model's output names\n",
    "        dynamic_axes={\n",
    "            \"input_ids\": {\n",
    "                0: \"batch_size\",\n",
    "                1: \"sequence_length\",\n",
    "            },  # variable length axes\n",
    "            \"attention_mask\": {0: \"batch_size\", 1: \"sequence_length\"},\n",
    "            \"output\": {0: \"batch_size\"},\n",
    "        },\n",
    "        keep_initializers_as_inputs=False,  # optimization for model size\n",
    "        verbose=False,\n",
    "    )\n",
    "    print(f\"Model exported to ONNX format at {save_path}\")\n",
    "\n",
    "\n",
    "def optimize_onnx_model(\n",
    "    onnx_model_path, optimized_model_path=None, quantize=True, quantization_type=\"int8\"\n",
    "):\n",
    "    import onnx\n",
    "    from onnxruntime.transformers import optimizer\n",
    "    from onnxruntime.transformers.fusion_options import FusionOptions\n",
    "    from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "    import onnx\n",
    "\n",
    "    if optimized_model_path is None:\n",
    "        optimized_model_path = onnx_model_path\n",
    "\n",
    "    # Load the model\n",
    "    model = onnx.load(onnx_model_path)\n",
    "\n",
    "    # Skip BERT optimizer if the model was already optimized\n",
    "    if \"onnxruntime.transformers\" not in model.producer_name:\n",
    "        # Set up optimization options\n",
    "        opt_options = FusionOptions(\"bert\")\n",
    "        opt_options.enable_embed_layer_norm = True\n",
    "        opt_options.enable_attention = True\n",
    "        opt_options.enable_skip_layer_norm = True\n",
    "        opt_options.enable_gelu = True\n",
    "\n",
    "        # Create the optimizer\n",
    "        model_optimizer = optimizer.optimize_model(\n",
    "            onnx_model_path,\n",
    "            \"bert\",\n",
    "            num_heads=12,  # Use detected value for MiniLM\n",
    "            hidden_size=384,  # Adjust based on your model architecture\n",
    "            optimization_options=opt_options,\n",
    "        )\n",
    "\n",
    "        # Save optimized model\n",
    "        optimized_path = optimized_model_path.replace(\".onnx\", \"_optimized.onnx\")\n",
    "        model_optimizer.save_model_to_file(optimized_path)\n",
    "        print(f\"Optimized model saved to {optimized_path}\")\n",
    "    else:\n",
    "        # If already optimized, just use the original path\n",
    "        optimized_path = onnx_model_path\n",
    "        print(f\"Model already optimized, skipping optimization\")\n",
    "\n",
    "    # Quantize if requested\n",
    "    if quantize:\n",
    "        try:\n",
    "            if quantization_type == \"int8\":\n",
    "                quant_type = QuantType.QInt8\n",
    "            else:\n",
    "                quant_type = QuantType.QFloat16\n",
    "\n",
    "            quantized_path = optimized_path.replace(\n",
    "                \".onnx\", f\"_{quantization_type}.onnx\"\n",
    "            )\n",
    "\n",
    "            # Add DefaultTensorType to address the error\n",
    "            extra_options = {\"DefaultTensorType\": onnx.TensorProto.FLOAT}\n",
    "\n",
    "            quantize_dynamic(\n",
    "                optimized_path,\n",
    "                quantized_path,\n",
    "                weight_type=quant_type,\n",
    "                extra_options=extra_options,\n",
    "            )\n",
    "            print(f\"Quantized model ({quantization_type}) saved to {quantized_path}\")\n",
    "            return quantized_path\n",
    "        except Exception as e:\n",
    "            print(f\"Quantization failed with error: {e}\")\n",
    "            print(\"Returning optimized but non-quantized model\")\n",
    "            return optimized_path\n",
    "\n",
    "    return optimized_path\n",
    "\n",
    "\n",
    "def test_onnx_inference_performance(onnx_model_path, test_batch, num_runs=100):\n",
    "    import onnxruntime as ort\n",
    "    import time\n",
    "    import numpy as np\n",
    "\n",
    "    # Configure session options for best performance\n",
    "    sess_options = ort.SessionOptions()\n",
    "    sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n",
    "    sess_options.intra_op_num_threads = 0  # 0 means use all available threads\n",
    "    sess_options.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL\n",
    "\n",
    "    # Provide all providers in priority order - let ONNXRuntime decide\n",
    "    providers = [\n",
    "        \"CUDAExecutionProvider\",\n",
    "        \"TensorrtExecutionProvider\",\n",
    "        \"DmlExecutionProvider\",\n",
    "        \"OpenVINOExecutionProvider\",\n",
    "        \"ROCMExecutionProvider\",\n",
    "        \"CoreMLExecutionProvider\",\n",
    "        \"CPUExecutionProvider\",\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        session = ort.InferenceSession(\n",
    "            onnx_model_path,\n",
    "            sess_options=sess_options,\n",
    "            providers=providers,  # Let ONNX runtime choose available providers\n",
    "        )\n",
    "        print(f\"Using providers: {session.get_providers()}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to use custom providers. Error: {e}\")\n",
    "        print(\"Falling back to default providers\")\n",
    "        session = ort.InferenceSession(onnx_model_path)\n",
    "        print(f\"Using providers: {session.get_providers()}\")\n",
    "\n",
    "    # Prepare input\n",
    "    input_msg = test_batch[\"messages\"][:1]  # Just use first item for speed test\n",
    "    inputs = tokenizer_func(input_msg)\n",
    "\n",
    "    # Convert to numpy arrays for ONNX Runtime\n",
    "    ort_inputs = {\n",
    "        \"input_ids\": inputs[\"input_ids\"].cpu().numpy(),\n",
    "        \"attention_mask\": inputs[\"attention_mask\"].cpu().numpy(),\n",
    "    }\n",
    "\n",
    "    # Warm-up runs\n",
    "    for _ in range(10):\n",
    "        session.run([\"output\"], ort_inputs)\n",
    "\n",
    "    # Benchmark runs\n",
    "    start_time = time.time()\n",
    "    for _ in range(num_runs):\n",
    "        output = session.run([\"output\"], ort_inputs)\n",
    "    end_time = time.time()\n",
    "\n",
    "    avg_time = (end_time - start_time) / num_runs * 1000  # ms\n",
    "\n",
    "    print(f\"Average inference time: {avg_time:.2f} ms per sample\")\n",
    "    print(f\"Throughput: {1000/avg_time:.2f} samples/second\")\n",
    "\n",
    "    return avg_time\n",
    "\n",
    "\n",
    "def create_optimized_model_pipeline(\n",
    "    model, base_filename=\"text_classifier\", quantize=True\n",
    "):\n",
    "    model_paths = {}\n",
    "\n",
    "    # Step 1: Export original model\n",
    "    orig_path = f\"{base_filename}.onnx\"\n",
    "    export_model_to_onnx(model, orig_path)\n",
    "    model_paths[\"original\"] = orig_path\n",
    "\n",
    "    # Step 2: Optimize model\n",
    "    optimized_path = optimize_onnx_model(\n",
    "        orig_path, optimized_model_path=None, quantize=False\n",
    "    )\n",
    "    model_paths[\"optimized\"] = optimized_path\n",
    "\n",
    "    # Step 3: Create quantized versions\n",
    "    if quantize:\n",
    "        # INT8 quantization\n",
    "        int8_path = optimize_onnx_model(\n",
    "            optimized_path,\n",
    "            optimized_model_path=None,\n",
    "            quantize=True,\n",
    "            quantization_type=\"int8\",\n",
    "        )\n",
    "        model_paths[\"int8\"] = int8_path\n",
    "\n",
    "        # FP16 quantization\n",
    "        fp16_path = optimize_onnx_model(\n",
    "            optimized_path,\n",
    "            optimized_model_path=None,\n",
    "            quantize=True,\n",
    "            quantization_type=\"fp16\",\n",
    "        )\n",
    "        model_paths[\"fp16\"] = fp16_path\n",
    "\n",
    "    return model_paths\n",
    "\n",
    "\n",
    "def benchmark_all_models(model_paths, test_data):\n",
    "    results = {}\n",
    "\n",
    "    for model_type, path in model_paths.items():\n",
    "        print(f\"\\n===== Benchmarking {model_type} model =====\")\n",
    "        try:\n",
    "            latency = test_onnx_inference_performance(path, test_data)\n",
    "            results[model_type] = latency\n",
    "        except Exception as e:\n",
    "            print(f\"Error benchmarking {model_type} model: {e}\")\n",
    "            results[model_type] = None\n",
    "\n",
    "    # Print comparison\n",
    "    print(\"\\n===== Performance Comparison =====\")\n",
    "    for model_type, latency in results.items():\n",
    "        if latency is not None:\n",
    "            print(f\"{model_type.capitalize()} model: {latency:.2f} ms per sample\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to ONNX format at text_classifier.onnx\n",
      "Optimized model saved to text_classifier_optimized.onnx\n",
      "Model already optimized, skipping optimization\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model (int8) saved to text_classifier_optimized_int8.onnx\n",
      "Model already optimized, skipping optimization\n",
      "Quantization failed with error: QFloat16\n",
      "Returning optimized but non-quantized model\n"
     ]
    }
   ],
   "source": [
    "model_paths = create_optimized_model_pipeline(custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to ONNX format at text_classifier.onnx\n"
     ]
    }
   ],
   "source": [
    "export_model_to_onnx(custom_model, \"text_classifier.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = next(iter(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "\n",
    "def test_onnx_model(onnx_path, test_data):\n",
    "    \"\"\"Test an exported ONNX model with sample data.\"\"\"\n",
    "    # Create an ONNX Runtime session\n",
    "    session = ort.InferenceSession(onnx_path)\n",
    "\n",
    "    # Prepare input data (assuming test_data is a batch from your test_dataloader)\n",
    "    input_msg = test_data[\"messages\"]\n",
    "    inputs = tokenizer_func(input_msg)\n",
    "\n",
    "    # Run inference\n",
    "    onnx_inputs = {\n",
    "        \"input_ids\": inputs[\"input_ids\"].numpy(),\n",
    "        \"attention_mask\": inputs[\"attention_mask\"].numpy(),\n",
    "    }\n",
    "\n",
    "    onnx_outputs = session.run(None, onnx_inputs)\n",
    "\n",
    "    # Process outputs\n",
    "    predicted_labels = onnx_outputs[0].argmax(axis=1)\n",
    "\n",
    "    print(f\"ONNX model predictions: {predicted_labels}\")\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ONNX model predictions: [1 2 0 0 0 2 0 2 2 2 2 0 1 0 0 1 1 0 2 0 1 0 2 0 1 1 2 0 0 2 1 2 0 0 2 1 2\n",
      " 0 1 2 1 1 1 1 2 1 0 0 2 0 0 2 0 2 0 0 0 2 0 1 0 0 0 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 1, 0, 0, 1, 1, 0, 2, 0, 1, 0,\n",
       "       2, 0, 1, 1, 2, 0, 0, 2, 1, 2, 0, 0, 2, 1, 2, 0, 1, 2, 1, 1, 1, 1,\n",
       "       2, 1, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_onnx_model(\"text_classifier_optimized_int8.onnx\", test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_onnx_inference_performance(\"text_classifier_optimized_int8.onnx\", test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "load_dotenv()\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"../reports/model_metrics_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:# Extract domain information from the model column\n",
    "    results['domain'] = results['model'].apply(lambda x: x.split('_')[1])\n",
    "    results['embedding'] = results['model'].apply(lambda x: x.split('_')[2])\n",
    "    results['model'] = results['model'].apply(lambda x: x.split('_')[0])\n",
    "    results['latency'] = results['latency'] / 1_000_000\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by model, domain, and embedding type and calculate mean metrics\n",
    "grouped_results = results.groupby(['model', 'domain']).agg({\n",
    "    'accuracy': 'mean',\n",
    "    'recall': 'mean',\n",
    "    'precision': 'mean',\n",
    "    'cost': 'mean',\n",
    "    'latency': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Convert latency to log scale for better visualization\n",
    "grouped_results['log_latency'] = np.log10(grouped_results['latency'])\n",
    "\n",
    "# Save the grouped results to a CSV file\n",
    "grouped_results.to_csv(\"../reports/grouped_metrics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define a consistent color scheme to use in both visualizations\n",
    "domain_colors = {'law': 'cornflowerblue', 'healthcare': 'orange', 'finance': 'mediumseagreen'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart comparing model accuracy across domains\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Pivot the data to get models as index and domains as columns\n",
    "accuracy_by_domain_model = grouped_results.pivot_table(\n",
    "    values='precision',\n",
    "    index='model',\n",
    "    columns='domain',\n",
    "    aggfunc='mean'\n",
    ")\n",
    "\n",
    "# Plot the bar chart with custom colors\n",
    "ax = accuracy_by_domain_model.plot(kind='bar', figsize=(14, 8), width=0.7, color=[domain_colors[col] for col in accuracy_by_domain_model.columns])\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Average Model Precision by Domain', fontsize=16)\n",
    "plt.xlabel('Model Type', fontsize=14)\n",
    "plt.ylabel('Average Precision (%)', fontsize=14)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.legend(title='Domain', fontsize=12)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.2f', padding=3, fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "# Group by model and calculate mean values for latency and precision\n",
    "mean_grouped_results = grouped_results.groupby('model').mean(numeric_only=True).reset_index()\n",
    "\n",
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(figsize=(12, 8), dpi=100)\n",
    "\n",
    "# Define markers and colors for different model types\n",
    "markers = {\n",
    "    'SVM': 'o',\n",
    "    'XGBoost': 's',\n",
    "    'fastText': '^',\n",
    "    'gpt4o-mini': 'D',\n",
    "    'modernbert': 'p'\n",
    "}\n",
    "colors = {\n",
    "    'SVM': '#1f77b4',         # blue\n",
    "    'XGBoost': '#ff7f0e',       # orange\n",
    "    'fastText': '#2ca02c',      # green\n",
    "    'gpt4o-mini': '#d62728',    # red\n",
    "    'modernbert': '#9467bd'     # purple\n",
    "}\n",
    "\n",
    "# Create scatter plot with markers for models and colors for domains\n",
    "for idx, row in mean_grouped_results.iterrows():\n",
    "    model = row['model']\n",
    "    plt.scatter(row['latency'], row['precision'],\n",
    "                marker=markers.get(model, '*'),\n",
    "                color=colors.get(model, 'gray'),\n",
    "                s=280,\n",
    "                edgecolor='black',\n",
    "                linewidth=1.5,\n",
    "                alpha=0.8,\n",
    "                zorder=10)\n",
    "\n",
    "    # Add labels to each point with a styled annotation box\n",
    "    label_text = f\"{model}\"\n",
    "    bbox_props = {\n",
    "        \"boxstyle\": 'round,pad=0.5',\n",
    "        \"fc\": colors.get(model, 'gray'),\n",
    "        \"ec\": \"black\",\n",
    "        \"alpha\": 0.7,\n",
    "        \"lw\": 1.5\n",
    "    }\n",
    "    plt.annotate(label_text,\n",
    "                 xy=(row['latency'], row['precision']),\n",
    "                 xytext=(15, 0),\n",
    "                 textcoords='offset points',\n",
    "                 fontsize=12,\n",
    "                 fontweight='bold',\n",
    "                 color='white',\n",
    "                 bbox=bbox_props,\n",
    "                 zorder=11)\n",
    "\n",
    "# Add a horizontal line for average precision\n",
    "avg_precision = mean_grouped_results['precision'].mean()\n",
    "plt.axhline(y=avg_precision, color='gray', linestyle='--', alpha=0.7, linewidth=2,\n",
    "            label=f'Avg Precision: {avg_precision:.2f}')\n",
    "\n",
    "# Calculate and add a vertical line for average latency\n",
    "avg_latency = mean_grouped_results['latency'].mean()\n",
    "plt.axvline(x=avg_latency, color='gray', linestyle='--', alpha=0.7, linewidth=2,\n",
    "            label=f'Avg Latency: {avg_latency:.2f}')\n",
    "\n",
    "# Use logarithmic scale for x-axis to better visualize differences\n",
    "plt.xscale('log')\n",
    "\n",
    "# Create custom legend for models (and add average lines)\n",
    "legend_elements = [\n",
    "    Patch(facecolor=colors[model], edgecolor='black',\n",
    "          label=f\"{model} (Precision: {mean_grouped_results[mean_grouped_results['model'] == model]['precision'].values[0]:.2f})\")\n",
    "    for model in colors\n",
    "]\n",
    "legend_elements.append(Patch(facecolor='gray', alpha=0.7, label=f'Avg Precision: {avg_precision:.2f}'))\n",
    "legend_elements.append(Patch(facecolor='gray', alpha=0.7, label=f'Avg Latency: {avg_latency:.2f}'))\n",
    "plt.legend(handles=legend_elements, loc='upper right',\n",
    "           frameon=True, framealpha=0.9, edgecolor='black',\n",
    "           fontsize=10, title='Model Performance', title_fontsize=12)\n",
    "\n",
    "# Customize plot with title and axis labels\n",
    "plt.title('Model Performance: Precision vs. Latency', fontsize=20, fontweight='bold', pad=20)\n",
    "plt.xlabel('Latency (ms, log scale)', fontsize=16, labelpad=15)\n",
    "plt.ylabel('Precision', fontsize=16, labelpad=15)\n",
    "\n",
    "# Add background gradient\n",
    "gradient = np.linspace(0, 1, 100).reshape(-1, 1)\n",
    "plt.imshow(gradient, cmap=plt.cm.Blues, alpha=0.1, aspect='auto',\n",
    "           extent=[ax.get_xlim()[0], ax.get_xlim()[1], ax.get_ylim()[0], ax.get_ylim()[1]])\n",
    "\n",
    "# Add grid styling\n",
    "plt.grid(True, linestyle='--', alpha=0.4, linewidth=0.8)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Customize x-axis tick formatter\n",
    "ax.xaxis.set_major_formatter(FuncFormatter(lambda x, _: f'{x:.1f}'))\n",
    "\n",
    "# Get current axis limits for quadrant annotations\n",
    "x_min, x_max = ax.get_xlim()\n",
    "y_min, y_max = ax.get_ylim()\n",
    "\n",
    "# For the x-axis (log scale), compute the geometric mean for left/right quadrant centers\n",
    "q_left = np.exp((np.log(x_min) + np.log(avg_latency)) / 2)\n",
    "q_right = np.exp((np.log(avg_latency) + np.log(x_max)) / 2)\n",
    "# For the y-axis (linear), compute the arithmetic means for top/bottom quadrant centers\n",
    "q_bottom = (y_min + avg_precision) / 2\n",
    "q_top = (avg_precision + y_max) / 2\n",
    "\n",
    "# Annotate the quadrants\n",
    "# Top-left: Low Latency, High Precision (optimal performance)\n",
    "ax.text(q_left, q_top, 'High Precision\\nLow Latency', ha='center', va='center',\n",
    "        fontsize=12, fontweight='bold', color='black', alpha=0.8, zorder=12)\n",
    "# Bottom-left: Low Latency, Low Precision\n",
    "ax.text(q_left, q_bottom, 'Low Precision\\nLow Latency', ha='center', va='center',\n",
    "        fontsize=12, fontweight='bold', color='black', alpha=0.8, zorder=12)\n",
    "# Bottom-right: High Latency, Low Precision\n",
    "ax.text(q_right, q_bottom, 'Low Precision\\nHigh Latency', ha='center', va='center',\n",
    "        fontsize=12, fontweight='bold', color='black', alpha=0.8, zorder=12)\n",
    "\n",
    "# Add a subtle box around the plot\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(1.5)\n",
    "    spine.set_color('#333333')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"deep\")\n",
    "sns.set_context(\"paper\", font_scale=1.2)\n",
    "\n",
    "# Group data by model and calculate mean latency\n",
    "latency_by_model = grouped_results.groupby('model')['latency'].mean().sort_values()\n",
    "\n",
    "# Create the bar plot with improved styling\n",
    "fig = plt.figure(figsize=(14, 8), dpi=100)\n",
    "ax = fig.add_subplot(111)  # Correctly create the axis object\n",
    "\n",
    "bars = plt.bar(latency_by_model.index, latency_by_model.values,\n",
    "               color=sns.color_palette(\"viridis\", len(latency_by_model)),\n",
    "               edgecolor='black', linewidth=1.5, alpha=0.85,\n",
    "               width=0.6)\n",
    "\n",
    "# Add value labels on top of bars with better formatting\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    display_value = f'{height:.2f} ms'\n",
    "\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height * 1.05,\n",
    "             display_value, ha='center', va='bottom',\n",
    "             fontsize=10, fontweight='bold', color='black')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Average Inference Latency by Model Type', fontsize=18, fontweight='bold', pad=20)\n",
    "plt.xlabel('Model Type', fontsize=14, labelpad=10)\n",
    "plt.ylabel('Average Latency (ms, log scale)', fontsize=14, labelpad=10)\n",
    "\n",
    "# Better grid\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "# Improved x-axis labels\n",
    "plt.xticks(rotation=30, ha='right', fontsize=12)\n",
    "\n",
    "# Use logarithmic scale with better formatting\n",
    "plt.yscale('log')\n",
    "ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{x:.1f}'))\n",
    "\n",
    "# Add a light background color to highlight the chart area\n",
    "ax.set_facecolor('#f8f9fa')\n",
    "\n",
    "# Add subtle spines\n",
    "for spine in ax.spines.values():\n",
    "    spine.set_linewidth(0.8)\n",
    "    spine.set_color('#333333')\n",
    "\n",
    "# Add light shading for visual appeal\n",
    "plt.axhspan(latency_by_model.min()*0.95, latency_by_model.max()*1.1, alpha=0.05, color='blue')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-validation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

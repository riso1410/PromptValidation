{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5786d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import statistics\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from fastembed import TextEmbedding\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import dataloader\n",
    "import util\n",
    "\n",
    "util.set_seed(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6a7294",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dataloader.get_domain_data()\n",
    "eval_datasets = dataloader.get_eval_datasets()\n",
    "batch_data = dataloader.get_batch_data()\n",
    "\n",
    "batch_sizes = [1, 32, 64, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c3e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "baai_embedding = TextEmbedding(\n",
    "    model_name=\"BAAI/bge-small-en-v1.5\", providers=[\"CPUExecutionProvider\"]\n",
    ")\n",
    "mini_embedding = TextEmbedding(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    providers=[\"CPUExecutionProvider\"],\n",
    ")\n",
    "\n",
    "tfidf_embedding = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf6e8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_dataset = next(iter(datasets.values()))[\"prompt\"]\n",
    "train_prompts = first_dataset.sample(frac=0.8, random_state=22)\n",
    "\n",
    "tfidf_embedding.fit(train_prompts)\n",
    "\n",
    "with open(f\"models/tfidf.pkl\", \"wb\") as f:\n",
    "    pkl.dump(tfidf_embedding, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee2b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_models = {\n",
    "    \"mini\": mini_embedding,\n",
    "    \"tf_idf\": tfidf_embedding,\n",
    "    \"baai\": baai_embedding,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33151981",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013a3bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain, dataset in datasets.items():\n",
    "    train_data = dataset.sample(frac=0.8).reset_index(drop=True)\n",
    "    test_data = dataset.drop(train_data.index).reset_index(drop=True)\n",
    "\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    prediction_times = []\n",
    "\n",
    "    # Skip embedding models if we're waiting for healthcare fastText\n",
    "    for model_name, embedding_model in embedding_models.items():\n",
    "        embed_times: float = None\n",
    "\n",
    "        # Add timing for embedding creation\n",
    "        if model_name == \"tf_idf\":\n",
    "            start_time = time.perf_counter_ns()\n",
    "            # Convert sparse matrices to dense for consistency\n",
    "            train_embeds = embedding_model.transform(train_data[\"prompt\"])\n",
    "            test_embeds = embedding_model.transform(test_data[\"prompt\"])\n",
    "            end_time = time.perf_counter_ns()\n",
    "            embed_times = end_time - start_time\n",
    "        else:\n",
    "            # Time the embedding process for training data\n",
    "            start_time = time.perf_counter_ns()\n",
    "            train_embeds = np.array(list(embedding_model.embed(train_data[\"prompt\"])))\n",
    "            test_embeds = np.array(list(embedding_model.embed(test_data[\"prompt\"])))\n",
    "            end_time = time.perf_counter_ns()\n",
    "            embed_times = end_time - start_time\n",
    "\n",
    "        mean_embed_time = embed_times / len(train_data + test_data)\n",
    "\n",
    "        # Train and evaluate SVM model\n",
    "        util.train_and_evaluate_model(\n",
    "            model_name=\"SVM\",\n",
    "            train_embeds=train_embeds,\n",
    "            test_embeds=test_embeds,\n",
    "            train_labels=train_data[\"label\"],\n",
    "            test_labels=test_data[\"label\"],\n",
    "            domain=domain,\n",
    "            embed_model=model_name,\n",
    "            save_path=f\"models/SVM_{domain}_{model_name}.pkl\",\n",
    "            embedding_time=mean_embed_time,\n",
    "            training=True,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b758447d",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf426782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "tfidf_embedding = pkl.load(open(\"models/tfidf.pkl\", \"rb\"))\n",
    "\n",
    "embedding_models = {\n",
    "    \"mini\": mini_embedding,\n",
    "    \"tf_idf\": tfidf_embedding,\n",
    "    \"baai\": baai_embedding,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a8bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SVM models\n",
    "with open(f\"models/SVM_finance_{embedding_model}.pkl\", \"rb\") as f:\n",
    "    svm_finance = pkl.load(f)\n",
    "with open(f\"models/SVM_healthcare_{embedding_model}.pkl\", \"rb\") as f:\n",
    "    svm_healthcare = pkl.load(f)\n",
    "with open(f\"models/SVM_law_{embedding_model}.pkl\", \"rb\") as f:\n",
    "    svm_law = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1d4d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "for embed_model_name, embedding_model in embedding_models:\n",
    "    for domain, inference_df in eval_datasets.items():\n",
    "        # Get actual labels once\n",
    "        actuals_ml = inference_df[\"label\"].tolist()\n",
    "\n",
    "        # Get embeddings based on model type\n",
    "        if embedding_model == \"tf_idf\":\n",
    "            test_embeds = embedding_model.transform(inference_df[\"prompt\"])\n",
    "        else:\n",
    "            start_time = time.perf_counter_ns()\n",
    "            if embedding_model == \"mini\":\n",
    "                test_embeds = np.array(\n",
    "                    list(mini_embedding.embed(inference_df[\"prompt\"]))\n",
    "                )\n",
    "            else:  # baai\n",
    "                test_embeds = np.array(\n",
    "                    list(baai_embedding.embed(inference_df[\"prompt\"]))\n",
    "                )\n",
    "            end_time = time.perf_counter_ns()\n",
    "            embed_times = end_time - start_time\n",
    "            mean_embed_time = embed_times / len(inference_df)\n",
    "\n",
    "        predictions_svm = []\n",
    "        prediction_times_svm = []\n",
    "\n",
    "        # Make predictions\n",
    "        for test_embed in test_embeds:\n",
    "            test_embed = test_embed.reshape(1, -1)\n",
    "\n",
    "            # SVM predictions\n",
    "            start_time = time.perf_counter_ns()\n",
    "            pred_finance = svm_finance.predict(test_embed)\n",
    "            pred_healthcare = svm_healthcare.predict(test_embed)\n",
    "            pred_law = svm_law.predict(test_embed)\n",
    "            end_time = time.perf_counter_ns()\n",
    "\n",
    "            prediction_times_svm.append(end_time - start_time)\n",
    "            predictions_svm.append(\n",
    "                0\n",
    "                if (\n",
    "                    pred_finance[0] == 1\n",
    "                    or pred_healthcare[0] == 1\n",
    "                    or pred_law[0] == 1\n",
    "                )\n",
    "                else 1\n",
    "            )\n",
    "\n",
    "        # Evaluate results\n",
    "        util.evaluate_run(\n",
    "            predictions=predictions_svm,\n",
    "            true_labels=actuals_ml,\n",
    "            latency=statistics.mean(prediction_times_svm),\n",
    "            domain=domain,\n",
    "            embed_model=embedding_model,\n",
    "            model_name=\"SVM\",\n",
    "            train_acc=0.0,\n",
    "            cost=0.0,\n",
    "            training=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221c96c0",
   "metadata": {},
   "source": [
    "# Batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for embedding_model in [\"mini\", \"baai\", \"tf_idf\"]:    \n",
    "    svm_batch_results = []\n",
    "\n",
    "    for batch_size in batch_sizes:\n",
    "        \n",
    "        batches = [\n",
    "            batch_data[i : i + batch_size] for i in range(0, len(batch_data), batch_size)\n",
    "        ]\n",
    "        for batch in batches:\n",
    "            num_batches += 1\n",
    "\n",
    "            batch_metrics = {\n",
    "                \"embed_time\": 0,\n",
    "                \"svm_law_time\": 0,\n",
    "                \"svm_finance_time\": 0,\n",
    "                \"svm_health_time\": 0,\n",
    "            }\n",
    "\n",
    "            # Time embeddings\n",
    "            start_time = time.perf_counter()\n",
    "            if embedding_model == \"tf_idf\":\n",
    "                embeds = tfidf_embedding.transform(batch)\n",
    "            elif embedding_model == \"mini\":\n",
    "                embeds = np.array(list(mini_embedding.embed(batch)))\n",
    "            else: # baai\n",
    "                embeds = np.array(list(baai_embedding.embed(batch)))\n",
    "            batch_metrics['embed_time'] += time.perf_counter() - start_time\n",
    "\n",
    "            # Get all predictions and time them\n",
    "            start_time = time.perf_counter()\n",
    "            svm_law_preds = svm_law.predict(embeds)\n",
    "            batch_metrics['svm_law_time'] += time.perf_counter() - start_time\n",
    "\n",
    "            start_time = time.perf_counter()\n",
    "            svm_finance_preds = svm_finance.predict(embeds)\n",
    "            batch_metrics['svm_finance_time'] += time.perf_counter() - start_time\n",
    "\n",
    "            start_time = time.perf_counter() \n",
    "            svm_health_preds = svm_healthcare.predict(embeds)\n",
    "            batch_metrics['svm_health_time'] += time.perf_counter() - start_time\n",
    "            # Combine predictions - 0 only if all predict 0\n",
    "            svm_batch_preds = [1 if (l or f or h) else 0\n",
    "                                for l,f,h in zip(svm_law_preds, svm_finance_preds, svm_health_preds)]\n",
    "            \n",
    "            # Record results for this batch size (averaged)\n",
    "            svm_batch_results.append({\n",
    "                \"batch_size\": batch_size,\n",
    "                \"time_taken_embed\": batch_metrics['embed_time'],\n",
    "                \"time_taken_law\": batch_metrics['svm_law_time'],\n",
    "                \"time_taken_finance\": batch_metrics['svm_finance_time'],\n",
    "                \"time_taken_healthcare\": batch_metrics['svm_health_time'],\n",
    "                \"results\": svm_batch_preds,\n",
    "                \"model_name\": \"svm\",\n",
    "                \"embedding_model\": embedding_model,\n",
    "                \"embedding\": True\n",
    "            })\n",
    "\n",
    "    pd.DataFrame(svm_batch_results).to_csv(f\"data/results/batch_svm_{embedding_model}.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

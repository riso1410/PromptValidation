{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e781c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statistics\n",
    "import time\n",
    "import fasttext\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "import dataloader\n",
    "import util\n",
    "\n",
    "util.set_seed(22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c39ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dataloader.get_domain_data()\n",
    "eval_datasets = dataloader.get_eval_datasets()\n",
    "batch_data = dataloader.get_batch_data()\n",
    "\n",
    "batch_sizes = [1, 32, 64, 128, 256]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049a3e6",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e6b0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain, dataset in tqdm(datasets.items(), desc='Processing domains'):\n",
    "    # Convert to pandas DataFrame for consistent access\n",
    "    train_data = dataset.sample(frac=0.8).reset_index(drop=True)\n",
    "    test_data = dataset.drop(train_data.index).reset_index(drop=True)\n",
    "\n",
    "    train_path = 'data/fasttext/train.txt'\n",
    "    val_path = 'data/fasttext/valid.txt'\n",
    "\n",
    "    labeled_train = util.label_dataset(train_data)\n",
    "    labeled_test = util.label_dataset(test_data)\n",
    "\n",
    "    util.write_to_file(labeled_train, train_path)\n",
    "    util.write_to_file(labeled_test, val_path)\n",
    "\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    prediction_times = []\n",
    "\n",
    "    # fastText\n",
    "    fasttext_classifier = fasttext.train_supervised(\n",
    "        input=train_path,\n",
    "        autotuneValidationFile=val_path,\n",
    "        autotuneDuration=300,\n",
    "    )\n",
    "\n",
    "    train_predictions = []\n",
    "    for _, row in train_data.iterrows():\n",
    "        query = str(row[\"prompt\"])\n",
    "        prediction = fasttext_classifier.predict(query)\n",
    "        train_predictions.append(1 if prediction[0][0] == \"__label__1\" else 0)\n",
    "\n",
    "    train_acc = metrics.accuracy_score(train_data[\"label\"], train_predictions)\n",
    "\n",
    "    for _, row in tqdm(test_data.iterrows(), total=len(test_data)):\n",
    "        text = str(row[\"prompt\"])\n",
    "\n",
    "        start_time = time.perf_counter_ns()\n",
    "        prediction = fasttext_classifier.predict(query)\n",
    "        end_time = time.perf_counter_ns()\n",
    "\n",
    "        prediction_times.append(end_time - start_time)\n",
    "        predictions.append(1 if prediction[0][0] == \"__label__1\" else 0)\n",
    "        actuals.append(row[\"label\"])\n",
    "\n",
    "    mean_prediction_time = statistics.mean(prediction_times)\n",
    "\n",
    "    util.evaluate_run(\n",
    "        predictions=predictions,\n",
    "        true_labels=actuals,\n",
    "        domain=domain,\n",
    "        model_name=\"fastText\",\n",
    "        embed_model=\"fastText\",\n",
    "        latency=mean_prediction_time,\n",
    "        train_acc=train_acc,\n",
    "        training=True,\n",
    "    )\n",
    "\n",
    "    fasttext_classifier.save_model(f\"models/fastText_{domain}_fasttext.bin\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e19c259",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f41b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_law = fasttext.load_model(\"models/fastText_law_fasttext.bin\")\n",
    "fasttext_finance = fasttext.load_model(\"models/fastText_finance_fasttext.bin\")\n",
    "fasttext_healthcare = fasttext.load_model(\"models/fastText_healthcare_fasttext.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb24e252",
   "metadata": {},
   "outputs": [],
   "source": [
    "for domain, inference_df in eval_datasets.items():\n",
    "    actuals_ft = []\n",
    "    predictions_ft = []\n",
    "    prediction_times_ft = []\n",
    "    \n",
    "    for _, row in tqdm(inference_df.iterrows(), total=len(inference_df)):\n",
    "        text = str(row[\"prompt\"])\n",
    "\n",
    "        try:\n",
    "            start_time = time.perf_counter_ns()\n",
    "\n",
    "            # Predictions from all three classifiers\n",
    "            prediction_finance = fasttext_finance.predict(query)\n",
    "            prediction_healthcare = fasttext_healthcare.predict(query)\n",
    "            prediction_law = fasttext_law.predict(query)\n",
    "\n",
    "            end_time = time.perf_counter_ns()\n",
    "            prediction_times_ft.append(end_time - start_time)\n",
    "\n",
    "            predictions_ft.append(\n",
    "                0\n",
    "                if (\n",
    "                    prediction_finance[0][0] == \"__label__1\"\n",
    "                    or prediction_healthcare[0][0] == \"__label__1\"\n",
    "                    or prediction_law[0][0] == \"__label__1\"\n",
    "                )\n",
    "                else 1\n",
    "            )\n",
    "            actuals_ft.append(row[\"label\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row: {e}\")\n",
    "            continue\n",
    "\n",
    "    util.evaluate_run(\n",
    "        predictions=predictions_ft,\n",
    "        true_labels=actuals_ft,\n",
    "        latency=statistics.mean(prediction_times_ft),\n",
    "        domain=domain,\n",
    "        embed_model=\"fastText\",\n",
    "        model_name=\"fastText\",\n",
    "        train_acc=0.0,\n",
    "        cost=0.0,\n",
    "        training=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d5c304",
   "metadata": {},
   "source": [
    "# Batch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4874409",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_results = []\n",
    "\n",
    "for batch_size in tqdm(batch_sizes, desc='Processing batch sizes'):\n",
    "    all_results = []\n",
    "    num_batches = 0\n",
    "    # create batches from batch_data\n",
    "    batches = [\n",
    "        batch_data[i : i + batch_size] for i in range(0, len(batch_data), batch_size)\n",
    "    ]\n",
    "    for batch in tqdm(batches, desc=f'Processing batches (size={batch_size})'):\n",
    "        num_batches += 1\n",
    "        batch_metrics = {\n",
    "            \"time_taken_law\": 0,\n",
    "            \"time_taken_finance\": 0,  \n",
    "            \"time_taken_healthcare\": 0\n",
    "        }\n",
    "\n",
    "        batch_prompt = [prompt.replace(\"\\n\", \"\") for prompt in batch]\n",
    "        \n",
    "        # Time law predictions\n",
    "        start_time = time.perf_counter()\n",
    "        law_preds = fasttext_law.predict(batch_prompt)\n",
    "        batch_metrics['time_taken_law'] += time.perf_counter() - start_time\n",
    "\n",
    "        # Time finance predictions\n",
    "        start_time = time.perf_counter()\n",
    "        finance_preds = fasttext_finance.predict(batch_prompt)\n",
    "        batch_metrics['time_taken_finance'] += time.perf_counter() - start_time\n",
    "\n",
    "        # Time healthcare predictions\n",
    "        start_time = time.perf_counter()\n",
    "        health_preds = fasttext_healthcare.predict(batch_prompt)\n",
    "        batch_metrics['time_taken_healthcare'] += time.perf_counter() - start_time\n",
    "\n",
    "        results =[]\n",
    "        for prediction_finance, prediction_healthcare, prediction_law in zip(finance_preds[0], health_preds[0], law_preds[0]):\n",
    "                results.append({\n",
    "                'finance': 1 if prediction_finance[0] == \"__label__1\" else 0,\n",
    "                'healthcare': 1 if prediction_healthcare[0] == \"__label__1\" else 0,\n",
    "                'law': 1 if prediction_law[0] == \"__label__1\" else 0\n",
    "            })\n",
    "\n",
    "        batch_results.append({\n",
    "            \"batch_size\": batch_size,\n",
    "            \"time_taken_embed\": 0,\n",
    "            \"time_taken_law\": batch_metrics['time_taken_law'],\n",
    "            \"time_taken_finance\": batch_metrics['time_taken_finance'],\n",
    "            \"time_taken_healthcare\": batch_metrics['time_taken_healthcare'],\n",
    "            \"results\": results,\n",
    "            \"model_name\": \"fasttext\",\n",
    "            \"embedding_model\": \"fasttext\",\n",
    "            \"embedding\": False\n",
    "        })\n",
    "\n",
    "pd.DataFrame(batch_results).to_csv(\"data/results/batch_fasttext.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a3d52e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

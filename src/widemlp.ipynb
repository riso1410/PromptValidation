{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d777b5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "try:\n",
    "    import wandb\n",
    "    USE_WANDB = True\n",
    "except ImportError:\n",
    "    USE_WANDB = False\n",
    "    print(\"wandb not installed, skipping wandb logging\")\n",
    "\n",
    "import dataloader\n",
    "from widemlp import MLP, inverse_document_frequency, prepare_inputs_optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98896520",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "DEVICE = (\n",
    "    torch.device(\"cuda:0\")\n",
    "    if torch.cuda.is_available()\n",
    "    else torch.device(\"cpu\")\n",
    ")\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "SEED = 42\n",
    "MODEL_NAME = \"\"\n",
    "EPOCHS = 128\n",
    "NUM_CLASSES = 3\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "TRAIN_LOGGING_STEPS = 1\n",
    "EVAL_LOGGING_STEPS = 100\n",
    "THRESHOLD = 0.5\n",
    "DATASET_SIZE = 15_000\n",
    "LOG_WANDB = True\n",
    "PATH = \"widemlp-3cls-v3-1l.pt\"\n",
    "TEST_SPLIT = 0.2\n",
    "NUM_HIDDEN_LAYERS = 1\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b7fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find cuda devices\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA devices:\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"  {i}: {torch.cuda.get_device_name(i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d507f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if LOG_WANDB:\n",
    "    wandb.init(project=\"ood-widemlp\")\n",
    "    wandb.config.update(\n",
    "        {\n",
    "            \"seed\": SEED,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"gradient_accumulation_steps\": GRADIENT_ACCUMULATION_STEPS,\n",
    "            \"train_logging_steps\": TRAIN_LOGGING_STEPS,\n",
    "            \"eval_logging_steps\": EVAL_LOGGING_STEPS,\n",
    "            \"threshold\": THRESHOLD,\n",
    "            \"test_split\": TEST_SPLIT,\n",
    "            \"num_hidden_layers\": NUM_HIDDEN_LAYERS,\n",
    "            \"num_classes\": NUM_CLASSES,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_seed(seed: int = 42) -> None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def load_data(path: str, eval_size: int = 0.2) -> Dataset:\n",
    "    df = pd.read_json(path) if path.endswith(\".json\") else pd.read_csv(path)\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "    dataset.shuffle(seed=42)\n",
    "    split_dataset = dataset.train_test_split(test_size=eval_size)\n",
    "    return split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43394833",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b313d49",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c1bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataloader.get_train_datasets(\n",
    "    dataset_size=DATASET_SIZE, split=TEST_SPLIT\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    data[\"train\"], batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    data[\"test\"], batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb36567",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1a5e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [\n",
    "    tokenizer.encode(raw_doc, padding=False, truncation=True, max_length=None)\n",
    "    for raw_doc in data[\"train\"][\"text\"]\n",
    "]\n",
    "idf = inverse_document_frequency(docs, len(tokenizer))\n",
    "model = MLP(\n",
    "    vocab_size=len(tokenizer),\n",
    "    num_hidden_layers=NUM_HIDDEN_LAYERS,\n",
    "    num_classes=NUM_CLASSES,\n",
    "    idf=idf,\n",
    "    problem_type=\"multi_label_classification\",\n",
    ")\n",
    "model.to(DEVICE)\n",
    "model.idf = model.idf.to(DEVICE) if model.idf is not None else None\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5059978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_one_hot(arr1, arr2):\n",
    "    arr1 = np.array(arr1)\n",
    "    arr2 = np.array(arr2)\n",
    "\n",
    "    if arr1.shape != arr2.shape:\n",
    "        raise ValueError(\"Input arrays must have the same shape.\")\n",
    "\n",
    "    num_samples = arr1.shape[0]\n",
    "    if num_samples == 0:\n",
    "        return 0.0  # Return 0 if no samples\n",
    "\n",
    "    correct_predictions = 0\n",
    "    for i in range(num_samples):\n",
    "        if np.array_equal(arr1[i], arr2[i]):  # Compare row by row for equality\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / num_samples\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0032e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy_one_hot(arr1, arr2):\n",
    "    arr1 = np.array(arr1)\n",
    "    arr2 = np.array(arr2)\n",
    "\n",
    "    if arr1.shape != arr2.shape:\n",
    "        raise ValueError(\"Input arrays must have the same shape.\")\n",
    "\n",
    "    num_samples = arr1.shape[0]\n",
    "    if num_samples == 0:\n",
    "        return 0.0  # Return 0 if no samples\n",
    "\n",
    "    correct_predictions = 0\n",
    "    for i in range(num_samples):\n",
    "        if np.array_equal(arr1[i], arr2[i]):  # Compare row by row for equality\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / num_samples\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def evaluate(\n",
    "    model: torch.nn.Module,\n",
    "    valid_loader: torch.utils.data.DataLoader,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    threshold: float,\n",
    ") -> dict:\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    validation_losses = []\n",
    "    max_probs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            inputs = tokenizer(\n",
    "                batch[\"text\"],\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=False,\n",
    "                return_tensors=\"pt\",\n",
    "            ).to(DEVICE)\n",
    "            flat_inputs, offsets = prepare_inputs_optimized(\n",
    "                inputs[\"input_ids\"], device=DEVICE\n",
    "            )\n",
    "            labels = batch[\"label\"].to(DEVICE, dtype=torch.long)\n",
    "            one_hot_targets = torch.nn.functional.one_hot(\n",
    "                labels, num_classes=NUM_CLASSES\n",
    "            ).to(DEVICE, dtype=torch.float32)\n",
    "\n",
    "            loss, logits = model(flat_inputs, offsets, one_hot_targets)\n",
    "            validation_losses.append(loss.item())\n",
    "            probabilities = torch.sigmoid(logits)  # -> 0-1\n",
    "            batch_predictions = []\n",
    "            for i in range(probabilities.size(0)):\n",
    "                sample_probabilities = probabilities[i]\n",
    "                max_probs.append(sample_probabilities.max().item())\n",
    "                thresholded_labels_indices = torch.where(\n",
    "                    sample_probabilities > threshold\n",
    "                )[0]\n",
    "                if len(thresholded_labels_indices) > 1:\n",
    "                    best_label_index = thresholded_labels_indices[\n",
    "                        torch.argmax(sample_probabilities[thresholded_labels_indices])\n",
    "                    ]\n",
    "                    prediction_vector = torch.zeros(NUM_CLASSES, dtype=torch.int)\n",
    "                    prediction_vector[best_label_index] = 1\n",
    "                    batch_predictions.append(prediction_vector.cpu().numpy())\n",
    "                else:\n",
    "                    predictions = (sample_probabilities > threshold).int()\n",
    "                    batch_predictions.append(predictions.cpu().numpy())\n",
    "            all_predictions.extend(batch_predictions)\n",
    "            all_labels.extend(one_hot_targets.cpu().numpy())\n",
    "\n",
    "    avg_validation_loss = np.mean(validation_losses)\n",
    "\n",
    "    all_predictions_np = np.array(all_predictions)\n",
    "    all_labels_np = np.array(all_labels)\n",
    "    scores = {\n",
    "        \"validation_loss\": avg_validation_loss,\n",
    "        \"accuracy\": calculate_accuracy_one_hot(all_predictions_np, all_labels_np),\n",
    "        \"max_probs\": np.mean(max_probs),\n",
    "    }\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f501593",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()\n",
    "for _epoch in range(EPOCHS):\n",
    "    step = 0\n",
    "    batch_train_loss = []\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        model.train()\n",
    "        inputs = tokenizer(\n",
    "            batch[\"text\"],\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=False,\n",
    "        )\n",
    "        flat_inputs, offsets = prepare_inputs_optimized(\n",
    "            inputs[\"input_ids\"], device=DEVICE\n",
    "        )\n",
    "        labels = batch[\"label\"].to(DEVICE, dtype=torch.long)\n",
    "        one_hot_targets = torch.nn.functional.one_hot(\n",
    "            labels, num_classes=NUM_CLASSES\n",
    "        ).to(DEVICE, dtype=torch.float32)\n",
    "        # inputs[\"label\"] = one_hot_targets\n",
    "        loss, logits = model(flat_inputs, offsets, one_hot_targets)\n",
    "        loss.backward()\n",
    "        step += 1  # noqa: SIM113\n",
    "        batch_train_loss.append(loss.item())\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "        if step % TRAIN_LOGGING_STEPS == 0:\n",
    "            accuracy = np.mean(batch_train_loss)\n",
    "            if LOG_WANDB:\n",
    "                wandb.log({\"train_loss\": float(accuracy), \"epoch\": _epoch})\n",
    "            else:\n",
    "                print(f\"Step {step}, Train Loss: {accuracy:.4f}\")\n",
    "        if step % EVAL_LOGGING_STEPS == 0:\n",
    "            scores = evaluate(model, valid_loader, tokenizer, threshold=0.1)\n",
    "            if LOG_WANDB:\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        \"validation_loss\": float(scores[\"validation_loss\"]),\n",
    "                        # \"test/macro_f1\": float(scores[\"macro_f1\"]),\n",
    "                        # \"test/micro_f1\": float(scores[\"micro_f1\"]),\n",
    "                        # \"test/macro_recall\": float(scores[\"macro_recall\"]),\n",
    "                        # \"test/micro_recall\": float(scores[\"micro_recall\"]),\n",
    "                        # \"test/macro_precision\": float(scores[\"macro_precision\"]),\n",
    "                        # \"test/micro_precision\": float(scores[\"micro_precision\"]),\n",
    "                        \"test/max_probs\": float(scores[\"max_probs\"]),\n",
    "                        \"test/accuracy\": float(scores[\"accuracy\"]),\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Step {step}, Validation Loss: {scores['validation_loss']:.4f}, Macro F1: {scores['macro_f1']:.4f}, Micro F1: {scores['micro_f1']:.4f}\"\n",
    "                )\n",
    "if LOG_WANDB:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b20054c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    PATH,\n",
    ")\n",
    "torch.save(idf, f\"{PATH.replace(\".pt\", \"_idf.pt\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1516f94b",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9467350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dataloader.get_eval_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db7048",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = dataloader.get_train_datasets(dataset_size=DATASET_SIZE, split=TEST_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9a913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"train\"].to_pandas().to_csv(\"train_domain.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836b226a",
   "metadata": {},
   "source": [
    "# MLP 3cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257bbc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(\n",
    "    model_path: str, idf_path: str, num_classes: int, num_hidden_layers: int\n",
    ") -> MLP:\n",
    "    idf = torch.load(idf_path).to(DEVICE)\n",
    "    checkpoint = torch.load(\n",
    "        model_path, weights_only=True, map_location=torch.device(DEVICE)\n",
    "    )\n",
    "    # print checkpoint keys\n",
    "    wide_mlp = MLP(\n",
    "        vocab_size=len(tokenizer),\n",
    "        num_hidden_layers=num_hidden_layers,\n",
    "        num_classes=num_classes,\n",
    "        idf=idf,\n",
    "        problem_type=\"multi_label_classification\",\n",
    "    )\n",
    "    wide_mlp.to(DEVICE)\n",
    "    wide_mlp.idf = idf if wide_mlp.idf is not None else None\n",
    "    wide_mlp.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "    wide_mlp.eval()\n",
    "    print(f\"Successfully loaded PyTorch model on {DEVICE}\")\n",
    "    return wide_mlp\n",
    "\n",
    "\n",
    "def inference(\n",
    "    model: torch.nn.Module,\n",
    "    text: str,\n",
    "    tokenizer: AutoTokenizer,\n",
    "    threshold: float,\n",
    ") -> dict:\n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=False,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(DEVICE)\n",
    "    flat_inputs, offsets = prepare_inputs_optimized(inputs[\"input_ids\"], device=DEVICE)\n",
    "\n",
    "    logits = model(flat_inputs, offsets)\n",
    "    probabilities = torch.sigmoid(logits)  # -> 0-1\n",
    "    batch_predictions = []\n",
    "    for i in range(probabilities.size(0)):\n",
    "        sample_probabilities = probabilities[i]\n",
    "        thresholded_labels_indices = torch.where(sample_probabilities > threshold)[0]\n",
    "        if len(thresholded_labels_indices) >= 1:\n",
    "            best_label_index = thresholded_labels_indices[\n",
    "                torch.argmax(sample_probabilities[thresholded_labels_indices])\n",
    "            ]\n",
    "            prediction_vector = torch.zeros(NUM_CLASSES, dtype=torch.int)\n",
    "            prediction_vector[best_label_index] = 1\n",
    "            batch_predictions.append(prediction_vector.cpu().numpy())\n",
    "        else:\n",
    "            # predictions = (sample_probabilities > threshold).int()\n",
    "            batch_predictions.append(np.array([0, 0, 0]))\n",
    "    all_predictions.extend(batch_predictions)\n",
    "\n",
    "    all_predictions_np = np.array(all_predictions)\n",
    "    return all_predictions_np\n",
    "\n",
    "\n",
    "models = [\n",
    "    (\"widemlp-23-30.pt\", 3, \"widemlp-3cls-v3_idf.pt\"),\n",
    "    (\"widemlp-3cls-v3.pt\", 10, \"widemlp-3cls-v3_idf.pt\"),\n",
    "    (\"widemlp-3cls-v3-1l.pt\", 1, \"widemlp-3cls-v3-1l_idf.pt\"),\n",
    "    # (\"widemlp-3cls-v2.pt\",3, \"widemlp-3cls-v2_idf.pt\"),\n",
    "    # (\"widemlp-3cls-v3-3l.pt\",3, \"widemlp-3cls-v3-3l_idf.pt\")\n",
    "    # (\"widemlp-3cls-v3-64l.pt\",64, \"widemlp-3cls-v3-64l_idf.pt\"),\n",
    "    # (\"widemlp-3cls-v3-128l.pt\",128, \"widemlp-3cls-v3-128l_idf.pt\")\n",
    "]\n",
    "\n",
    "# Model: widemlp-23-30.pt - 3, Mean : 92.26000000000002, Scores: [92.30000000000001, 92.30000000000001, 92.25555555555556, 92.23333333333333, 92.21111111111111], Thresholds: [0.4, 0.5, 0.75, 0.9, 0.99]\n",
    "# Model: widemlp-3cls-v3.pt - 10, Mean : 85.6, Scores: [85.6, 85.6, 85.6, 85.6, 85.6], Thresholds: [0.4, 0.5, 0.75, 0.9, 0.99]\n",
    "# Model: widemlp-3cls-v2.pt - 3, Mean : 34.63777777777778, Scores: [36.72222222222222, 35.82222222222222, 34.044444444444444, 33.41111111111111, 33.18888888888889], Thresholds: [0.4, 0.5, 0.75, 0.9, 0.99]\n",
    "# Model: widemlp-3cls-v3-3l.pt - 3, Mean : 71.39333333333335, Scores: [71.54444444444444, 71.52222222222223, 71.43333333333334, 71.33333333333334, 71.13333333333334], Thresholds: [0.4, 0.5, 0.75, 0.9, 0.99]\n",
    "# Model: widemlp-3cls-v3-64l.pt - 64, Mean : 33.18888888888889, Scores: [33.18888888888889, 33.18888888888889, 33.18888888888889, 33.18888888888889, 33.18888888888889], Thresholds: [0.4, 0.5, 0.75, 0.9, 0.99]\n",
    "# Model: widemlp-3cls-v3-128l.pt - 128, Mean : 33.18888888888889, Scores: [33.18888888888889, 33.18888888888889, 33.18888888888889, 33.18888888888889, 33.18888888888889], Thresholds: [0.4, 0.5, 0.75, 0.9, 0.99]\n",
    "for model_name, num_hidden_layers, idf_path in models:\n",
    "    model_scores = []\n",
    "    wide_mlp = load_model(\n",
    "        model_path=model_name,\n",
    "        idf_path=idf_path,\n",
    "        num_classes=3,\n",
    "        num_hidden_layers=num_hidden_layers,\n",
    "    )\n",
    "    for threshold in tqdm([0.5, 0.75, 0.9, 0.99]):\n",
    "        data = []\n",
    "        ood = pd.read_csv(\"data/ood_eval.csv\")\n",
    "        for i in ood[\"prompt\"].values:\n",
    "            results = inference(wide_mlp, i, tokenizer, threshold)\n",
    "            data.append(results[0])\n",
    "        ood[\"pred\"] = data\n",
    "        ood[\"pred\"] = ood[\"pred\"].apply(lambda x: np.argmax(x))\n",
    "        ood.to_csv(\n",
    "            f\"data/mlp/ood_eval_{model_name}_threshold_{threshold}.csv\", index=False\n",
    "        )\n",
    "        data = []\n",
    "        domain = pd.read_csv(\"data/domain_eval.csv\")\n",
    "        for i in domain[\"text\"].values:\n",
    "            results = inference(wide_mlp, i, tokenizer, threshold)\n",
    "            data.append(results[0])\n",
    "        domain[\"pred\"] = data\n",
    "        domain[\"pred\"] = domain[\"pred\"].apply(lambda x: np.argmax(x))\n",
    "        domain.to_csv(\n",
    "            f\"data/mlp/domain_eval_{model_name}_threshold_{threshold}.csv\", index=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894f6511",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_batch(\n",
    "    model: torch.nn.Module,\n",
    "    batch_texts: list[str],\n",
    "    tokenizer: AutoTokenizer,\n",
    "    threshold: float,\n",
    "    num_classes: int = NUM_CLASSES,\n",
    "    device: torch.device = DEVICE,\n",
    ") -> np.ndarray:\n",
    "    model.eval()\n",
    "    all_predictions_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        inputs = tokenizer(\n",
    "            batch_texts,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=tokenizer.model_max_length,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(device)\n",
    "\n",
    "        input_ids_batch = inputs[\"input_ids\"]\n",
    "        flat_inputs, offsets = prepare_inputs_optimized(input_ids_batch, device=device)\n",
    "        logits = model(flat_inputs, offsets=offsets)\n",
    "        probabilities = torch.sigmoid(logits)\n",
    "        above_threshold_mask = probabilities > threshold\n",
    "        has_prediction = torch.any(above_threshold_mask, dim=1)\n",
    "        probs_for_argmax = torch.where(above_threshold_mask, probabilities, -1.0)\n",
    "        best_indices = torch.argmax(probs_for_argmax, dim=1)\n",
    "        batch_predictions = torch.zeros(\n",
    "            probabilities.size(0), num_classes, dtype=torch.int, device=device\n",
    "        )\n",
    "        batch_predictions.scatter_(1, best_indices.unsqueeze(1), 1)\n",
    "        final_batch_predictions = batch_predictions * has_prediction.unsqueeze(1).int()\n",
    "        all_predictions_list.append(final_batch_predictions.cpu())\n",
    "    if not all_predictions_list:\n",
    "        return np.empty((0, num_classes), dtype=np.int_)\n",
    "    all_predictions_np = torch.cat(all_predictions_list, dim=0).numpy()\n",
    "\n",
    "    return all_predictions_np\n",
    "\n",
    "\n",
    "models = [\n",
    "    (\"widemlp-23-30.pt\", 3, \"widemlp-3cls-v3_idf.pt\"),\n",
    "    (\"widemlp-3cls-v3.pt\", 10, \"widemlp-3cls-v3_idf.pt\"),\n",
    "    (\"widemlp-3cls-v3-1l.pt\", 1, \"widemlp-3cls-v3-1l_idf.pt\"),\n",
    "]\n",
    "\n",
    "for model_name, num_hidden_layers, idf_path in models:\n",
    "    model_scores = []\n",
    "    wide_mlp = load_model(\n",
    "        model_path=model_name,\n",
    "        idf_path=idf_path,\n",
    "        num_classes=3,\n",
    "        num_hidden_layers=num_hidden_layers,\n",
    "    )\n",
    "    batch_results = []\n",
    "    for batch_size in tqdm([1, 32, 64, 128, 256]):\n",
    "        data = pd.read_csv(\"data/batch_data.csv\")\n",
    "\n",
    "        batches = [\n",
    "            data[\"prompt\"].values.tolist()[i : i + batch_size]\n",
    "            for i in range(0, len(data[\"prompt\"].values.tolist()), batch_size)\n",
    "        ]\n",
    "        for batch in batches:\n",
    "            start_time = time.perf_counter()\n",
    "            results = inference_batch(wide_mlp, batch, tokenizer, 0.85)\n",
    "            end_time = time.perf_counter()\n",
    "            elapsed_time = end_time - start_time\n",
    "            batch_results.append(\n",
    "                {\n",
    "                    \"batch_size\": batch_size,\n",
    "                    \"time_taken\": elapsed_time,\n",
    "                    \"results\": results,\n",
    "                    \"model_name\": model_name,\n",
    "                }\n",
    "            )\n",
    "    pd.DataFrame(batch_results).to_csv(\n",
    "        f\"data/batch/{model_name}-batch.csv\", index=False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prompt-validation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
